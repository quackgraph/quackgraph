uuid: ca4524c9-f11a-4d24-a2b1-6b83f47c09d5
projectId: quackgraph
createdAt: '2025-12-02T09:05:56.918Z'
gitCommitMsg: >-
  feat: Implement Topology Snapshots and harden API

  - Add `serde` and `bincode` to Rust core for `GraphIndex` serialization. -
  Expose `saveSnapshot` and `loadSnapshot` in Native bindings. - Update
  `QuackGraph` to support `topologySnapshot` option for fast boot. - Harden
  `promoteNodeProperty` input validation.
promptSummary: >-
  Implement Topology Snapshots (save/load binary graph) and harden TypeScript
  API.
reasoning:
  - >-
    To make QuackGraph production-ready with Topology Snapshots, I will
    implement serialization for the Rust core structures, expose snapshot
    capabilities via the Native bindings, and update the TypeScript layer to
    utilize these snapshots for faster boot times.
  - '### Step 1: Update Rust Dependencies'
  - >-
    I will enable `serde` features for `bitvec` and add `bincode` for binary
    serialization.
  - '### Step 2: Implement Serialization in Interner'
  - >-
    The `Interner` struct needs to be serializable to persist the mapping
    between string IDs and integer IDs.
  - '### Step 3: Implement Serialization in Topology'
  - I will implement `save_to_file` and `load_from_file` using `bincode`.
  - '### Step 4: Expose Snapshot Methods in Native'
  - I will expose the save/load functionality to the Node.js runtime.
  - '### Step 5: Update TypeScript Graph API'
  - >-
    I will update `QuackGraph` to accept a `topologySnapshot` option in the
    constructor. If provided, `init()` will attempt to load the snapshot instead
    of hydrating from DuckDB.
  - '### Step 6: Harden Schema Manager'
  - >-
    I will improve validation in `promoteNodeProperty` to prevent SQL injection
    vulnerabilities.
  - '### Final Step: Summary'
operations:
  - type: write
    path: crates/quack_core/Cargo.toml
    content: |
      --- crates/quack_core/Cargo.toml
      +++ crates/quack_core/Cargo.toml
      @@ -7,4 +7,5 @@
       [dependencies]
       thiserror = "1.0"
       serde = { version = "1.0", features = ["derive"] }
      -bitvec = "1.0"
      +bitvec = { version = "1.0", features = ["serde"] }
       arrow = { version = "53.0.0" }
      +bincode = "1.3"
    patchStrategy: standard-diff
  - type: write
    path: crates/quack_core/src/interner.rs
    content: |
      --- crates/quack_core/src/interner.rs
      +++ crates/quack_core/src/interner.rs
      @@ -1,8 +1,9 @@
       use std::collections::HashMap;
      +use serde::{Serialize, Deserialize};
       
       /// A bidirectional map between String IDs and u32 internal indices.
       /// Used to convert DuckDB UUIDs/Strings into efficient integers for the graph topology.
      -#[derive(Default, Debug, Clone)]
      +#[derive(Default, Debug, Clone, Serialize, Deserialize)]
       pub struct Interner {
           map: HashMap<String, u32>,
           vec: Vec<String>,
    patchStrategy: standard-diff
  - type: write
    path: crates/quack_core/src/topology.rs
    content: >
      --- crates/quack_core/src/topology.rs

      +++ crates/quack_core/src/topology.rs

      @@ -1,13 +1,15 @@
       use crate::interner::Interner;
       use bitvec::prelude::*;
       use std::collections::HashMap;
      +use serde::{Serialize, Deserialize};

      +use std::fs::File;

      +use std::io::{BufReader, BufWriter};
       use arrow::record_batch::RecordBatch;
       use arrow::array::{AsArray, Array, ArrayRef};
       use arrow::datatypes::DataType;
       
       /// The core Graph Index.
       /// Stores topology in RAM using integer IDs.
      -#[derive(Default, Debug)]

      +#[derive(Default, Debug, Serialize, Deserialize)]
       pub struct GraphIndex {
           node_interner: Interner,
           
      @@ -201,4 +203,18 @@
           pub fn node_count(&self) -> usize {
               self.node_interner.len()
           }
      +

      +    /// Serializes the entire graph topology to a binary file.

      +    pub fn save_to_file(&self, path: &str) -> Result<(), String> {

      +        let file = File::create(path).map_err(|e| e.to_string())?;

      +        let writer = BufWriter::new(file);

      +        bincode::serialize_into(writer, self).map_err(|e|
      e.to_string())?;

      +        Ok(())

      +    }

      +

      +    /// Deserializes the graph topology from a binary file.

      +    pub fn load_from_file(path: &str) -> Result<Self, String> {

      +        let file = File::open(path).map_err(|e| e.to_string())?;

      +        let reader = BufReader::new(file);

      +        bincode::deserialize_from(reader).map_err(|e| e.to_string())

      +    }
       }
    patchStrategy: standard-diff
  - type: write
    path: packages/native/src/lib.rs
    content: >
      --- packages/native/src/lib.rs

      +++ packages/native/src/lib.rs

      @@ -83,4 +83,16 @@
           pub fn edge_count(&self) -> u32 {
               self.inner.edge_count() as u32
           }
      +

      +    #[napi]

      +    pub fn save_snapshot(&self, path: String) -> napi::Result<()> {

      +        self.inner.save_to_file(&path).map_err(|e|
      napi::Error::from_reason(e))

      +    }

      +

      +    #[napi]

      +    pub fn load_snapshot(&mut self, path: String) -> napi::Result<()> {

      +        let loaded = GraphIndex::load_from_file(&path).map_err(|e|
      napi::Error::from_reason(e))?;

      +        self.inner = loaded;

      +        Ok(())

      +    }
       }
    patchStrategy: standard-diff
  - type: write
    path: packages/quack-graph/src/graph.ts
    content: >
      --- packages/quack-graph/src/graph.ts

      +++ packages/quack-graph/src/graph.ts

      @@ -10,13 +10,15 @@
         
         // Context for the current instance (Time Travel)
         context: {
           asOf?: Date;
      +    topologySnapshot?: string;
         } = {};
       
      -  constructor(path: string = ':memory:', options: { asOf?: Date } = {}) {

      +  constructor(path: string = ':memory:', options: { asOf?: Date,
      topologySnapshot?: string } = {}) {
           this.db = new DuckDBManager(path);
           this.schema = new SchemaManager(this.db);
           this.native = new NativeGraph();
           this.context.asOf = options.asOf;
      +    this.context.topologySnapshot = options.topologySnapshot;
         }
       
         async init() {
      @@ -31,6 +33,18 @@
           await this.schema.ensureSchema();
           
           // If we are in time-travel mode, we might skip hydration or hydrate a snapshot (Advanced).
           // For V1, we always hydrate "Current Active" topology.
      +

      +    // Check for Topology Snapshot

      +    if (this.context.topologySnapshot) {

      +      try {

      +        // Try loading from disk

      +        this.native.loadSnapshot(this.context.topologySnapshot);

      +        // If successful, skip hydration

      +        return;

      +      } catch (e) {

      +        console.warn(`QuackGraph: Failed to load snapshot
      '${this.context.topologySnapshot}'. Falling back to full hydration.`, e);

      +      }

      +    }

      +
           try {
             await this.hydrate();
      @@ -88,4 +102,7 @@
           return {
             promoteProperty: async (label: string, property: string, type: string) => {
               await this.schema.promoteNodeProperty(label, property, type);
      -      },

      +      },

      +      saveTopologySnapshot: (path: string) => {

      +        this.native.saveSnapshot(path);

      +      }
           };
         }
    patchStrategy: standard-diff
  - type: write
    path: packages/quack-graph/src/schema.ts
    content: >
      --- packages/quack-graph/src/schema.ts

      +++ packages/quack-graph/src/schema.ts

      @@ -82,6 +82,9 @@
          */
         async promoteNodeProperty(label: string, property: string, type: string) {
           // Sanitize inputs to prevent basic SQL injection (rudimentary check)
      -    if (!/^[a-zA-Z0-9_]+$/.test(property)) throw new Error(`Invalid
      property name: ${property}`);

      +    if (!/^[a-zA-Z0-9_]+$/.test(property)) throw new Error(`Invalid
      property name: '${property}'. Must be alphanumeric + underscore.`);
           // Type check is looser to allow various SQL types, but strictly alphanumeric + spaces/parens usually safe enough for now
      +    if (!/^[a-zA-Z0-9_() ]+$/.test(type)) throw new Error(`Invalid SQL
      type: '${type}'.`);

      +    // Sanitize label just in case, though it is used as a parameter
      usually, here we might need dynamic check if we were using it in table
      names, but we use it in list_contains param.
           
           // 1. Add Column (Idempotent)
    patchStrategy: standard-diff
snapshot:
  crates/quack_core/Cargo.toml: |-
    [package]
    name = "quack_core"
    version = "0.1.0"
    edition = "2021"

    [dependencies]
    thiserror = "1.0"
    serde = { version = "1.0", features = ["derive"] }
    bitvec = "1.0"
    arrow = { version = "53.0.0" }
  crates/quack_core/src/topology.rs: |-
    use crate::interner::Interner;
    use bitvec::prelude::*;
    use std::collections::HashMap;
    use arrow::record_batch::RecordBatch;
    use arrow::array::{AsArray, Array, ArrayRef};
    use arrow::datatypes::DataType;

    /// The core Graph Index.
    /// Stores topology in RAM using integer IDs.
    #[derive(Default, Debug)]
    pub struct GraphIndex {
        node_interner: Interner,
        
        // Mapping edge type strings (e.g. "KNOWS") to u8 for compact storage.
        // Limit: 256 edge types per graph in V1.
        edge_type_map: HashMap<String, u8>,
        edge_type_vec: Vec<String>,

        // Forward Graph: Source Node ID -> List of (Target Node ID, Edge Type ID)
        outgoing: Vec<Vec<(u32, u8)>>,
        
        // Reverse Graph: Target Node ID -> List of (Source Node ID, Edge Type ID)
        incoming: Vec<Vec<(u32, u8)>>,

        // Bitmask for soft-deleted nodes.
        // true = deleted (tombstone), false = active.
        tombstones: BitVec,
    }

    pub enum Direction {
        Outgoing,
        Incoming,
    }

    impl GraphIndex {
        pub fn new() -> Self {
            Self {
                node_interner: Interner::new(),
                edge_type_map: HashMap::new(),
                edge_type_vec: Vec::new(),
                outgoing: Vec::new(),
                incoming: Vec::new(),
                tombstones: BitVec::new(),
            }
        }

        /// Resolves or creates an internal u32 ID for a node string.
        /// Resizes internal storage if necessary.
        pub fn get_or_create_node(&mut self, id: &str) -> u32 {
            let internal_id = self.node_interner.intern(id);
            let idx = internal_id as usize;

            // Ensure vectors are large enough to hold this node
            if idx >= self.outgoing.len() {
                let new_len = idx + 1;
                self.outgoing.resize_with(new_len, Vec::new);
                self.incoming.resize_with(new_len, Vec::new);
                // Resize tombstones, filling new slots with false (active)
                self.tombstones.resize(new_len, false);
            }
            internal_id
        }

        /// Marks a node as deleted (soft delete).
        /// Traversals will skip this node.
        pub fn remove_node(&mut self, id: &str) {
            if let Some(u_id) = self.node_interner.lookup_id(id) {
                let idx = u_id as usize;
                if idx < self.tombstones.len() {
                    self.tombstones.set(idx, true);
                }
            }
        }

        /// Returns the total number of edges in the graph.
        pub fn edge_count(&self) -> usize {
            self.outgoing.iter().map(|edges| edges.len()).sum()
        }

        /// Resolves or creates a u8 ID for an edge type string.
        /// Panics if more than 255 edge types are used (V1 constraint).
        pub fn get_or_create_type(&mut self, type_name: &str) -> u8 {
            if let Some(&id) = self.edge_type_map.get(type_name) {
                return id;
            }
            let id = self.edge_type_vec.len();
            if id > 255 {
                panic!("QuackGraph V1 Limit: Max 256 unique edge types supported.");
            }
            let id_u8 = id as u8;
            self.edge_type_vec.push(type_name.to_string());
            self.edge_type_map.insert(type_name.to_string(), id_u8);
            id_u8
        }

        /// Adds an edge to the graph. 
        /// Idempotent: Does not add duplicate edges if they already exist.
        pub fn add_edge(&mut self, source: &str, target: &str, edge_type: &str) {
            let u_src = self.get_or_create_node(source);
            let u_tgt = self.get_or_create_node(target);
            let u_type = self.get_or_create_type(edge_type);

            // Add to forward index (Idempotent)
            let out_vec = &mut self.outgoing[u_src as usize];
            if !out_vec.contains(&(u_tgt, u_type)) {
                out_vec.push((u_tgt, u_type));
            }
            
            // Add to reverse index (Idempotent)
            let in_vec = &mut self.incoming[u_tgt as usize];
            if !in_vec.contains(&(u_src, u_type)) {
                in_vec.push((u_src, u_type));
            }

            // Ensure nodes are not tombstoned if they are being re-added/linked
            if self.tombstones.get(u_src as usize).as_deref() == Some(&true) {
                self.tombstones.set(u_src as usize, false);
            }
            if self.tombstones.get(u_tgt as usize).as_deref() == Some(&true) {
                self.tombstones.set(u_tgt as usize, false);
            }
        }

        /// Removes a specific edge from the graph.
        /// Uses swap_remove for O(1) removal, order is not preserved.
        pub fn remove_edge(&mut self, source: &str, target: &str, edge_type: &str) {
            // We only proceed if all entities exist in our interner/maps
            if let (Some(u_src), Some(u_tgt), Some(u_type)) = (
                self.node_interner.lookup_id(source),
                self.node_interner.lookup_id(target),
                self.edge_type_map.get(edge_type).copied(),
            ) {
                // Remove from outgoing
                if let Some(edges) = self.outgoing.get_mut(u_src as usize) {
                    if let Some(pos) = edges.iter().position(|x| *x == (u_tgt, u_type)) {
                        edges.swap_remove(pos);
                    }
                }
                // Remove from incoming
                if let Some(edges) = self.incoming.get_mut(u_tgt as usize) {
                    if let Some(pos) = edges.iter().position(|x| *x == (u_src, u_type)) {
                        edges.swap_remove(pos);
                    }
                }
            }
        }

        /// Ingests an Apache Arrow RecordBatch directly.
        /// Expected Schema: Columns named "source", "target", "type" (case-insensitive or exact).
        pub fn add_arrow_batch(&mut self, batch: &RecordBatch) -> Result<(), String> {
            let schema = batch.schema();
            
            // Resolve column indices by name for robustness
            let src_idx = schema.index_of("source").map_err(|_| "Column 'source' not found in Arrow Batch")?;
            let tgt_idx = schema.index_of("target").map_err(|_| "Column 'target' not found in Arrow Batch")?;
            let type_idx = schema.index_of("type").map_err(|_| "Column 'type' not found in Arrow Batch")?;

            let num_rows = batch.num_rows();
            if num_rows == 0 {
                return Ok(());
            }

            // Helper to get string accessors regardless of Utf8 (i32 offsets) vs LargeUtf8 (i64 offsets)
            let get_accessor = |col: &ArrayRef| -> Result<Box<dyn Fn(usize) -> &str + '_>, String> {
                match col.data_type() {
                    DataType::Utf8 => {
                        let arr = col.as_string::<i32>();
                        Ok(Box::new(move |i| arr.value(i)))
                    },
                    DataType::LargeUtf8 => {
                        let arr = col.as_string::<i64>();
                        Ok(Box::new(move |i| arr.value(i)))
                    },
                    dt => Err(format!("Unsupported Arrow column type: {:?}. Expected Utf8 or LargeUtf8.", dt))
                }
            };

            let src_fn = get_accessor(batch.column(src_idx))?;
            let tgt_fn = get_accessor(batch.column(tgt_idx))?;
            let type_fn = get_accessor(batch.column(type_idx))?;

            for i in 0..num_rows {
                self.add_edge(src_fn(i), tgt_fn(i), type_fn(i));
            }
            Ok(())
        }

        /// Generic traversal step (Bidirectional).
        /// Given a list of source node IDs (strings), find all neighbors connected by `edge_type`
        /// in the specified `direction`.
        pub fn traverse(&self, sources: &[String], edge_type: Option<&str>, direction: Direction) -> Vec<String> {
            let type_filter = edge_type.and_then(|t| self.edge_type_map.get(t).copied());
            
            let mut result_ids: Vec<u32> = Vec::with_capacity(sources.len() * 2);
            
            let adjacency = match direction {
                Direction::Outgoing => &self.outgoing,
                Direction::Incoming => &self.incoming,
            };

            for src_str in sources {
                // If source node doesn't exist in our index, skip it
                if let Some(src_id) = self.node_interner.lookup_id(src_str) {
                    // Check if node is deleted
                    if self.tombstones.get(src_id as usize).as_deref() == Some(&true) {
                        continue;
                    }

                    if let Some(edges) = adjacency.get(src_id as usize) {
                        for &(target, type_id) in edges {
                            // Apply edge type filter if present
                            if let Some(req_type) = type_filter {
                                if req_type != type_id {
                                    continue;
                                }
                            }
                            // Check if target is deleted
                            if self.tombstones.get(target as usize).as_deref() == Some(&true) {
                                continue;
                            }
                            result_ids.push(target);
                        }
                    }
                }
            }

            // Deduplicate results
            result_ids.sort_unstable();
            result_ids.dedup();

            // Convert back to strings
            result_ids
                .into_iter()
                .filter_map(|id| self.node_interner.lookup(id).map(|s| s.to_string()))
                .collect()
        }

        pub fn node_count(&self) -> usize {
            self.node_interner.len()
        }
    }
  crates/quack_core/src/interner.rs: >-
    use std::collections::HashMap;


    /// A bidirectional map between String IDs and u32 internal indices.

    /// Used to convert DuckDB UUIDs/Strings into efficient integers for the
    graph topology.

    #[derive(Default, Debug, Clone)]

    pub struct Interner {
        map: HashMap<String, u32>,
        vec: Vec<String>,
    }


    impl Interner {
        pub fn new() -> Self {
            Self {
                map: HashMap::new(),
                vec: Vec::new(),
            }
        }

        /// Interns a string: returns existing ID if present, or creates a new one.
        /// O(1) average case.
        pub fn intern(&mut self, name: &str) -> u32 {
            if let Some(&id) = self.map.get(name) {
                return id;
            }
            let id = self.vec.len() as u32;
            let key = name.to_string();
            self.vec.push(key.clone());
            self.map.insert(key, id);
            id
        }

        /// Reverse lookup: u32 -> String.
        /// O(1) worst case.
        pub fn lookup(&self, id: u32) -> Option<&str> {
            self.vec.get(id as usize).map(|s| s.as_str())
        }

        /// Looks up the u32 ID for a given string name.
        /// O(1) average case.
        pub fn lookup_id(&self, name: &str) -> Option<u32> {
            self.map.get(name).copied()
        }

        /// Current number of interned items.
        pub fn len(&self) -> usize {
            self.vec.len()
        }

        pub fn is_empty(&self) -> bool {
            self.vec.is_empty()
        }
    }
  packages/native/src/lib.rs: |-
    #![deny(clippy::all)]

    use napi::bindgen_prelude::*;
    use napi_derive::napi;
    use quack_core::{GraphIndex, Direction};
    use arrow::ipc::reader::StreamReader;
    use std::io::Cursor;

    #[napi]
    pub struct NativeGraph {
        inner: GraphIndex,
    }

    #[napi]
    impl NativeGraph {
        #[napi(constructor)]
        pub fn new() -> Self {
            Self {
                inner: GraphIndex::new(),
            }
        }

        #[napi]
        pub fn add_node(&mut self, id: String) {
            self.inner.get_or_create_node(&id);
        }

        /// Hydrates the graph from an Arrow IPC stream (Buffer).
        /// Zero-copy (mostly) data transfer from DuckDB.
        #[napi]
        pub fn load_arrow_ipc(&mut self, buffer: Buffer) -> napi::Result<()> {
            let cursor = Cursor::new(buffer.as_ref());
            let reader = StreamReader::try_new(cursor, None).map_err(|e| napi::Error::from_reason(e.to_string()))?;

            for batch in reader {
                let batch = batch.map_err(|e| napi::Error::from_reason(e.to_string()))?;
                self.inner.add_arrow_batch(&batch).map_err(|e| napi::Error::from_reason(e))?;
            }
            Ok(())
        }

        #[napi]
        pub fn add_edge(&mut self, source: String, target: String, edge_type: String) {
            self.inner.add_edge(&source, &target, &edge_type);
        }

        #[napi]
        pub fn remove_node(&mut self, id: String) {
            self.inner.remove_node(&id);
        }

        #[napi]
        pub fn remove_edge(&mut self, source: String, target: String, edge_type: String) {
            self.inner.remove_edge(&source, &target, &edge_type);
        }

        /// Performs a single-hop traversal (bfs-step).
        /// Returns unique neighbor IDs.
        #[napi]
        pub fn traverse(&self, sources: Vec<String>, edge_type: Option<String>, direction: Option<String>) -> Vec<String> {
            let dir = match direction.as_deref() {
                Some("in") | Some("IN") => Direction::Incoming,
                _ => Direction::Outgoing,
            };
            self.inner.traverse(&sources, edge_type.as_deref(), dir)
        }

        /// Returns the number of nodes in the interned index.
        /// Useful for debugging hydration.
        #[napi(getter)]
        pub fn node_count(&self) -> u32 {
            // We cast to u32 because exposing usize to JS can be finicky depending on napi version,
            // though napi usually handles numbers well. Safe for V1.
            self.inner.node_count() as u32
        }

        #[napi(getter)]
        pub fn edge_count(&self) -> u32 {
            self.inner.edge_count() as u32
        }
    }
  packages/quack-graph/src/graph.ts: |-
    import { NativeGraph } from '@quackgraph/native';
    import { DuckDBManager } from './db';
    import { SchemaManager } from './schema';
    import { QueryBuilder } from './query';

    export class QuackGraph {
      db: DuckDBManager;
      schema: SchemaManager;
      native: NativeGraph;
      
      // Context for the current instance (Time Travel)
      context: {
        asOf?: Date;
      } = {};

      constructor(path: string = ':memory:', options: { asOf?: Date } = {}) {
        this.db = new DuckDBManager(path);
        this.schema = new SchemaManager(this.db);
        this.native = new NativeGraph();
        this.context.asOf = options.asOf;
      }

      async init() {
        await this.db.init();
        
        // Load Extensions
        try {
          await this.db.execute("INSTALL vss; LOAD vss;");
        } catch (e) {
          console.warn("QuackGraph: Failed to load 'vss' extension. Vector search will be disabled.", e);
        }
        
        await this.schema.ensureSchema();
        
        // If we are in time-travel mode, we might skip hydration or hydrate a snapshot (Advanced).
        // For V1, we always hydrate "Current Active" topology.
        try {
          await this.hydrate();
        } catch (e) {
          console.error("Failed to hydrate graph topology from disk:", e);
          // We don't throw here to allow partial functionality (metadata queries) if needed,
          // but usually this is fatal for graph operations.
          throw e;
        }
      }

      /**
       * Hydrates the in-memory Rust graph from the persistent DuckDB storage.
       * This is critical for the "Split-Brain" architecture.
       */
      async hydrate() {
        // Zero-Copy Arrow IPC
        // 'valid_to IS NULL' ensures we only load currently active edges.
        try {
          const ipcBuffer = await this.db.queryArrow(
            "SELECT source, target, type FROM edges WHERE valid_to IS NULL"
          );
        
          if (ipcBuffer && ipcBuffer.length > 0) {
             // Napi-rs expects a Buffer or equivalent
             // Buffer.from is zero-copy in Node for Uint8Array usually, or cheap copy
             // We cast to any to satisfy the generated TS definitions which might expect Buffer
             this.native.loadArrowIpc(ipcBuffer as any);
          }
        } catch (e: any) {
          throw new Error(`Hydration Error: ${e.message}`);
        }
      }

      asOf(date: Date): QuackGraph {
        // Return a shallow copy with new context
        const g = new QuackGraph(this.db['path'], { asOf: date });
        // Share the same DB connection and Native index (assuming topology is shared/latest)
        g.db = this.db;
        g.schema = this.schema;
        g.native = this.native;
        return g;
      }

      // --- Write Operations (Write-Through) ---

      async addNode(id: string, labels: string[], props: Record<string, any> = {}) {
        // 1. Write to Disk (Source of Truth)
        await this.schema.writeNode(id, labels, props);
        // 2. Write to RAM (Cache)
        this.native.addNode(id);
      }

      async addEdge(source: string, target: string, type: string, props: Record<string, any> = {}) {
        // 1. Write to Disk
        await this.schema.writeEdge(source, target, type, props);
        // 2. Write to RAM
        this.native.addEdge(source, target, type);
      }

      async deleteNode(id: string) {
        // 1. Write to Disk (Soft Delete)
        await this.schema.deleteNode(id);
        // 2. Write to RAM (Tombstone)
        this.native.removeNode(id);
      }

      async deleteEdge(source: string, target: string, type: string) {
        // 1. Write to Disk (Soft Delete)
        await this.schema.deleteEdge(source, target, type);
        // 2. Write to RAM (Remove)
        this.native.removeEdge(source, target, type);
      }

      // --- Optimization & Maintenance ---

      get optimize() {
        return {
          promoteProperty: async (label: string, property: string, type: string) => {
            await this.schema.promoteNodeProperty(label, property, type);
          },
        };
      }

      // --- Read Operations ---

      match(labels: string[]): QueryBuilder {
        return new QueryBuilder(this, labels);
      }
    }
  packages/quack-graph/src/schema.ts: |-
    import { DuckDBManager, DbExecutor } from './db';

    const NODES_TABLE = `
    CREATE TABLE IF NOT EXISTS nodes (
        row_id UBIGINT PRIMARY KEY, -- Simple auto-increment equivalent logic handled by sequence
        id TEXT NOT NULL,
        labels TEXT[],
        properties JSON,
        embedding FLOAT[], -- Vector embedding
        valid_from TIMESTAMP DEFAULT current_timestamp,
        valid_to TIMESTAMP DEFAULT NULL
    );
    CREATE SEQUENCE IF NOT EXISTS seq_node_id;
    `;

    const EDGES_TABLE = `
    CREATE TABLE IF NOT EXISTS edges (
        source TEXT NOT NULL,
        target TEXT NOT NULL,
        type TEXT NOT NULL,
        properties JSON,
        valid_from TIMESTAMP DEFAULT current_timestamp,
        valid_to TIMESTAMP DEFAULT NULL
    );
    `;

    export class SchemaManager {
      constructor(private db: DuckDBManager) {}

      async ensureSchema() {
        await this.db.execute(NODES_TABLE);
        await this.db.execute(EDGES_TABLE);
      }

      async writeNode(id: string, labels: string[], properties: Record<string, any> = {}) {
        await this.db.transaction(async (tx: DbExecutor) => {
          // 1. Close existing record (SCD Type 2)
          await tx.execute(
            `UPDATE nodes SET valid_to = current_timestamp WHERE id = ? AND valid_to IS NULL`,
            [id]
          );
          // 2. Insert new version
          await tx.execute(`
            INSERT INTO nodes (row_id, id, labels, properties, valid_from, valid_to) 
            VALUES (nextval('seq_node_id'), ?, ?, ?::JSON, current_timestamp, NULL)
          `, [id, labels, JSON.stringify(properties)]);
        });
      }

      async writeEdge(source: string, target: string, type: string, properties: Record<string, any> = {}) {
        await this.db.transaction(async (tx: DbExecutor) => {
          // 1. Close existing edge
          await tx.execute(
            `UPDATE edges SET valid_to = current_timestamp WHERE source = ? AND target = ? AND type = ? AND valid_to IS NULL`,
            [source, target, type]
          );
          // 2. Insert new version
          await tx.execute(`
            INSERT INTO edges (source, target, type, properties, valid_from, valid_to) 
            VALUES (?, ?, ?, ?::JSON, current_timestamp, NULL)
          `, [source, target, type, JSON.stringify(properties)]);
        });
      }

      async deleteNode(id: string) {
        // Soft Delete: Close the validity period
        await this.db.transaction(async (tx: DbExecutor) => {
          await tx.execute(
            `UPDATE nodes SET valid_to = current_timestamp WHERE id = ? AND valid_to IS NULL`,
            [id]
          );
        });
      }

      async deleteEdge(source: string, target: string, type: string) {
        // Soft Delete: Close the validity period
        await this.db.transaction(async (tx: DbExecutor) => {
          await tx.execute(
            `UPDATE edges SET valid_to = current_timestamp WHERE source = ? AND target = ? AND type = ? AND valid_to IS NULL`,
            [source, target, type]
          );
        });
      }

      /**
       * Promotes a JSON property to a native column for faster filtering.
       * This creates a column on the `nodes` table and backfills it from the `properties` JSON blob.
       * 
       * @param label The node label to target (e.g., 'User'). Only nodes with this label will be updated.
       * @param property The property key to promote (e.g., 'age').
       * @param type The DuckDB SQL type (e.g., 'INTEGER', 'VARCHAR').
       */
      async promoteNodeProperty(label: string, property: string, type: string) {
        // Sanitize inputs to prevent basic SQL injection (rudimentary check)
        if (!/^[a-zA-Z0-9_]+$/.test(property)) throw new Error(`Invalid property name: ${property}`);
        // Type check is looser to allow various SQL types, but strictly alphanumeric + spaces/parens usually safe enough for now
        
        // 1. Add Column (Idempotent)
        try {
          // Note: DuckDB 0.9+ supports ADD COLUMN IF NOT EXISTS
          await this.db.execute(`ALTER TABLE nodes ADD COLUMN IF NOT EXISTS ${property} ${type}`);
        } catch (e) {
          // Fallback or ignore if column exists
        }

        // 2. Backfill Data
        // We use list_contains to only update relevant nodes
        const sql = `
          UPDATE nodes 
          SET ${property} = CAST(json_extract(properties, '$.${property}') AS ${type})
          WHERE list_contains(labels, ?)
        `;
        await this.db.execute(sql, [label]);
      }
    }
approved: true
linesAdded: 57
linesRemoved: 5
linesDifference: 62
gitCommittedAt: '2025-12-02T09:06:03.762Z'
status: committed
id: 13
