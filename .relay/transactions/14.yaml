uuid: 4f18a2b3-90cd-4e31-87ab-4318c892b1a1
projectId: quackgraph
createdAt: '2025-12-02T09:10:57.270Z'
gitCommitMsg: >-
  feat: production hardening (memory compaction, robust arrow ingest, vss
  checks)
promptSummary: >
  Executed production readiness plan. 

  1. Rust: Added `compact()` for memory optimization and case-insensitive column
  matching for Arrow ingestion.

  2. Native: Exposed `compact()` to JS.

  3. TS: Hardened `DuckDBManager` arrow fetching, safe buffer handling,
  capability checks for VSS, and query optimizations.
reasoning:
  - >-
    Here is the implementation of the production-readiness plan, hardening the
    Core Rust engine and polishing the TypeScript integration.
  - '### Part 1: Rust Core Hardening'
  - >-
    I will modify `topology.rs` to handle case-insensitive Arrow column names
    (common with different SQL projections) and add a `compact()` method to
    reclaim memory after the hydration phase.
  - Now I expose the `compact` method to the Native API.
  - '### Part 2: TypeScript DX & Integration Polish'
  - >-
    I will improve the `DuckDBManager` to be more robust when fetching Arrow
    streams, handling different versions of the underlying driver.
  - >-
    Next, update the main `QuackGraph` class to track capabilities (VSS) and
    trigger memory compaction after hydration.
  - >-
    Finally, harden the `QueryBuilder` to check for VSS capabilities and
    optimize empty traversals.
operations:
  - type: write
    path: crates/quack_core/src/topology.rs
    content: >
      --- crates/quack_core/src/topology.rs

      +++ crates/quack_core/src/topology.rs

      @@ -48,6 +48,16 @@
               }
           }
       
      +    /// Compacts internal vectors to minimize memory usage.

      +    /// Should be called after bulk hydration.

      +    pub fn compact(&mut self) {

      +        self.outgoing.shrink_to_fit();

      +        self.outgoing.iter_mut().for_each(|v| v.shrink_to_fit());

      +        self.incoming.shrink_to_fit();

      +        self.incoming.iter_mut().for_each(|v| v.shrink_to_fit());

      +        self.edge_type_vec.shrink_to_fit();

      +    }

      +
           /// Resolves or creates an internal u32 ID for a node string.
           /// Resizes internal storage if necessary.
           pub fn get_or_create_node(&mut self, id: &str) -> u32 {
      @@ -165,9 +175,12 @@
               let schema = batch.schema();
               
      -        // Resolve column indices by name for robustness

      -        let src_idx = schema.index_of("source").map_err(|_| "Column
      'source' not found in Arrow Batch")?;

      -        let tgt_idx = schema.index_of("target").map_err(|_| "Column
      'target' not found in Arrow Batch")?;

      -        let type_idx = schema.index_of("type").map_err(|_| "Column 'type'
      not found in Arrow Batch")?;

      +        // Resolve column indices by name for robustness
      (Case-Insensitive)

      +        let find_col = |name: &str| -> Result<usize, String> {

      +            schema.fields().iter().position(|f|
      f.name().eq_ignore_ascii_case(name))

      +                .ok_or_else(|| format!("Column '{}' not found in Arrow
      Batch. Available: {:?}", name, schema.fields().iter().map(|f|
      f.name()).collect::<Vec<_>>()))

      +        };

      +

      +        let src_idx = find_col("source")?;

      +        let tgt_idx = find_col("target")?;

      +        let type_idx = find_col("type")?;
       
               let num_rows = batch.num_rows();
    patchStrategy: standard-diff
  - type: write
    path: packages/native/src/lib.rs
    content: >
      --- packages/native/src/lib.rs

      +++ packages/native/src/lib.rs

      @@ -35,6 +35,13 @@
           }
       
      +    /// Compacts the graph's memory usage.

      +    /// Call this after hydration to reclaim unused capacity in the
      adjacency lists.

      +    #[napi]

      +    pub fn compact(&mut self) {

      +        self.inner.compact();

      +    }

      +
           #[napi]
           pub fn add_edge(&mut self, source: String, target: String, edge_type: String) {
               self.inner.add_edge(&source, &target, &edge_type);
    patchStrategy: standard-diff
  - type: write
    path: packages/quack-graph/src/db.ts
    content: >
      --- packages/quack-graph/src/db.ts

      +++ packages/quack-graph/src/db.ts

      @@ -87,6 +87,8 @@
             // duckdb-async instance holds 'db' property which is the native Database
             const rawDb = (db as any).db || db;
       
      +      if (!rawDb) return reject(new Error("Could not access underlying
      DuckDB Native instance."));

      +
             // Helper to merge multiple Arrow batches if necessary
             const mergeBatches = (batches: Uint8Array[]) => {
               if (batches.length === 0) return new Uint8Array(0);
      @@ -115,7 +117,14 @@
                try {
                   const rawConn = rawDb.connect();
      -            if (rawConn && typeof rawConn.arrowIPCAll === 'function') {

      +            

      +            // Handle case where rawDb is actually the connection itself
      (sometimes happens in certain pool configs)

      +            const target = typeof rawDb.arrowIPCAll === 'function' 

      +              ? rawDb 

      +              : (rawConn && typeof rawConn.arrowIPCAll === 'function' ?
      rawConn : null);

      +

      +            if (target) {

      -               rawConn.arrowIPCAll(sql, params, (err: any, result: any)
      => {

      +               target.arrowIPCAll(sql, params, (err: any, result: any) =>
      {
                         if (err) return reject(err);
                         if (Array.isArray(result)) {
    patchStrategy: standard-diff
  - type: write
    path: packages/quack-graph/src/graph.ts
    content: |
      --- packages/quack-graph/src/graph.ts
      +++ packages/quack-graph/src/graph.ts
      @@ -10,6 +10,10 @@
         schema: SchemaManager;
         native: NativeGraph;
         
      +  capabilities = {
      +    vss: false
      +  };
      +
         // Context for the current instance (Time Travel)
         context: {
           asOf?: Date;
      @@ -32,6 +36,7 @@
           // Load Extensions
           try {
             await this.db.execute("INSTALL vss; LOAD vss;");
      +      this.capabilities.vss = true;
           } catch (e) {
             console.warn("QuackGraph: Failed to load 'vss' extension. Vector search will be disabled.", e);
           }
      @@ -79,7 +84,14 @@
                // Buffer.from is zero-copy in Node for Uint8Array usually, or cheap copy
                // We cast to any to satisfy the generated TS definitions which might expect Buffer
      -         this.native.loadArrowIpc(ipcBuffer as any);
      +         const bufferForNapi = Buffer.isBuffer(ipcBuffer) 
      +            ? ipcBuffer 
      +            : Buffer.from(ipcBuffer);
      +            
      +         this.native.loadArrowIpc(bufferForNapi as any);
      +
      +         // Reclaim memory after burst hydration
      +         this.native.compact();
             }
           } catch (e: any) {
             throw new Error(`Hydration Error: ${e.message}`);
      @@ -93,6 +105,7 @@
           g.db = this.db;
           g.schema = this.schema;
           g.native = this.native;
      +    g.capabilities = { ...this.capabilities };
           return g;
         }
    patchStrategy: standard-diff
  - type: write
    path: packages/quack-graph/src/query.ts
    content: >
      --- packages/quack-graph/src/query.ts

      +++ packages/quack-graph/src/query.ts

      @@ -112,6 +112,9 @@
           let orderBy = '';
           let limit = '';
           if (this.vectorSearch) {
      +      if (!this.graph.capabilities.vss) {

      +        throw new Error("Vector Search (nearText) requires the 'vss'
      DuckDB extension, which failed to load.");

      +      }
             // Requires: array_distance(embedding, [1,2,3])
             // DuckDB VSS extension syntax
             const vectorStr = `[${this.vectorSearch.vector.join(',')}]`; // Inline vector for V1
      @@ -139,8 +142,10 @@
             // step.type is 'out' | 'in'
             // native.traverse(ids, edgeType, direction)
             currentIds = this.graph.native.traverse(currentIds, step.edge, step.type);
           }
       
      +    // Optimization: If traversal resulted in no nodes, stop early.

      +    if (currentIds.length === 0) return [];

      +
           // --- Step 3: DuckDB Hydration (Top Bun) ---
           // Objective: Fetch full properties for the resulting IDs, applying terminal filters.
       
      -    if (currentIds.length === 0) return [];

      -
           const finalConditions: string[] = [];
           const finalParams: any[] = [];
    patchStrategy: standard-diff
snapshot:
  crates/quack_core/src/topology.rs: |-
    use crate::interner::Interner;
    use bitvec::prelude::*;
    use std::collections::HashMap;
    use serde::{Serialize, Deserialize};
    use std::fs::File;
    use std::io::{BufReader, BufWriter};
    use arrow::record_batch::RecordBatch;
    use arrow::array::{AsArray, Array, ArrayRef};
    use arrow::datatypes::DataType;

    /// The core Graph Index.
    /// Stores topology in RAM using integer IDs.
    #[derive(Default, Debug, Serialize, Deserialize)]
    pub struct GraphIndex {
        node_interner: Interner,
        
        // Mapping edge type strings (e.g. "KNOWS") to u8 for compact storage.
        // Limit: 256 edge types per graph in V1.
        edge_type_map: HashMap<String, u8>,
        edge_type_vec: Vec<String>,

        // Forward Graph: Source Node ID -> List of (Target Node ID, Edge Type ID)
        outgoing: Vec<Vec<(u32, u8)>>,
        
        // Reverse Graph: Target Node ID -> List of (Source Node ID, Edge Type ID)
        incoming: Vec<Vec<(u32, u8)>>,

        // Bitmask for soft-deleted nodes.
        // true = deleted (tombstone), false = active.
        tombstones: BitVec,
    }

    pub enum Direction {
        Outgoing,
        Incoming,
    }

    impl GraphIndex {
        pub fn new() -> Self {
            Self {
                node_interner: Interner::new(),
                edge_type_map: HashMap::new(),
                edge_type_vec: Vec::new(),
                outgoing: Vec::new(),
                incoming: Vec::new(),
                tombstones: BitVec::new(),
            }
        }

        /// Resolves or creates an internal u32 ID for a node string.
        /// Resizes internal storage if necessary.
        pub fn get_or_create_node(&mut self, id: &str) -> u32 {
            let internal_id = self.node_interner.intern(id);
            let idx = internal_id as usize;

            // Ensure vectors are large enough to hold this node
            if idx >= self.outgoing.len() {
                let new_len = idx + 1;
                self.outgoing.resize_with(new_len, Vec::new);
                self.incoming.resize_with(new_len, Vec::new);
                // Resize tombstones, filling new slots with false (active)
                self.tombstones.resize(new_len, false);
            }
            internal_id
        }

        /// Marks a node as deleted (soft delete).
        /// Traversals will skip this node.
        pub fn remove_node(&mut self, id: &str) {
            if let Some(u_id) = self.node_interner.lookup_id(id) {
                let idx = u_id as usize;
                if idx < self.tombstones.len() {
                    self.tombstones.set(idx, true);
                }
            }
        }

        /// Returns the total number of edges in the graph.
        pub fn edge_count(&self) -> usize {
            self.outgoing.iter().map(|edges| edges.len()).sum()
        }

        /// Resolves or creates a u8 ID for an edge type string.
        /// Panics if more than 255 edge types are used (V1 constraint).
        pub fn get_or_create_type(&mut self, type_name: &str) -> u8 {
            if let Some(&id) = self.edge_type_map.get(type_name) {
                return id;
            }
            let id = self.edge_type_vec.len();
            if id > 255 {
                panic!("QuackGraph V1 Limit: Max 256 unique edge types supported.");
            }
            let id_u8 = id as u8;
            self.edge_type_vec.push(type_name.to_string());
            self.edge_type_map.insert(type_name.to_string(), id_u8);
            id_u8
        }

        /// Adds an edge to the graph. 
        /// Idempotent: Does not add duplicate edges if they already exist.
        pub fn add_edge(&mut self, source: &str, target: &str, edge_type: &str) {
            let u_src = self.get_or_create_node(source);
            let u_tgt = self.get_or_create_node(target);
            let u_type = self.get_or_create_type(edge_type);

            // Add to forward index (Idempotent)
            let out_vec = &mut self.outgoing[u_src as usize];
            if !out_vec.contains(&(u_tgt, u_type)) {
                out_vec.push((u_tgt, u_type));
            }
            
            // Add to reverse index (Idempotent)
            let in_vec = &mut self.incoming[u_tgt as usize];
            if !in_vec.contains(&(u_src, u_type)) {
                in_vec.push((u_src, u_type));
            }

            // Ensure nodes are not tombstoned if they are being re-added/linked
            if self.tombstones.get(u_src as usize).as_deref() == Some(&true) {
                self.tombstones.set(u_src as usize, false);
            }
            if self.tombstones.get(u_tgt as usize).as_deref() == Some(&true) {
                self.tombstones.set(u_tgt as usize, false);
            }
        }

        /// Removes a specific edge from the graph.
        /// Uses swap_remove for O(1) removal, order is not preserved.
        pub fn remove_edge(&mut self, source: &str, target: &str, edge_type: &str) {
            // We only proceed if all entities exist in our interner/maps
            if let (Some(u_src), Some(u_tgt), Some(u_type)) = (
                self.node_interner.lookup_id(source),
                self.node_interner.lookup_id(target),
                self.edge_type_map.get(edge_type).copied(),
            ) {
                // Remove from outgoing
                if let Some(edges) = self.outgoing.get_mut(u_src as usize) {
                    if let Some(pos) = edges.iter().position(|x| *x == (u_tgt, u_type)) {
                        edges.swap_remove(pos);
                    }
                }
                // Remove from incoming
                if let Some(edges) = self.incoming.get_mut(u_tgt as usize) {
                    if let Some(pos) = edges.iter().position(|x| *x == (u_src, u_type)) {
                        edges.swap_remove(pos);
                    }
                }
            }
        }

        /// Ingests an Apache Arrow RecordBatch directly.
        /// Expected Schema: Columns named "source", "target", "type" (case-insensitive or exact).
        pub fn add_arrow_batch(&mut self, batch: &RecordBatch) -> Result<(), String> {
            let schema = batch.schema();
            
            // Resolve column indices by name for robustness
            let src_idx = schema.index_of("source").map_err(|_| "Column 'source' not found in Arrow Batch")?;
            let tgt_idx = schema.index_of("target").map_err(|_| "Column 'target' not found in Arrow Batch")?;
            let type_idx = schema.index_of("type").map_err(|_| "Column 'type' not found in Arrow Batch")?;

            let num_rows = batch.num_rows();
            if num_rows == 0 {
                return Ok(());
            }

            // Helper to get string accessors regardless of Utf8 (i32 offsets) vs LargeUtf8 (i64 offsets)
            let get_accessor = |col: &ArrayRef| -> Result<Box<dyn Fn(usize) -> &str + '_>, String> {
                match col.data_type() {
                    DataType::Utf8 => {
                        let arr = col.as_string::<i32>();
                        Ok(Box::new(move |i| arr.value(i)))
                    },
                    DataType::LargeUtf8 => {
                        let arr = col.as_string::<i64>();
                        Ok(Box::new(move |i| arr.value(i)))
                    },
                    dt => Err(format!("Unsupported Arrow column type: {:?}. Expected Utf8 or LargeUtf8.", dt))
                }
            };

            let src_fn = get_accessor(batch.column(src_idx))?;
            let tgt_fn = get_accessor(batch.column(tgt_idx))?;
            let type_fn = get_accessor(batch.column(type_idx))?;

            for i in 0..num_rows {
                self.add_edge(src_fn(i), tgt_fn(i), type_fn(i));
            }
            Ok(())
        }

        /// Generic traversal step (Bidirectional).
        /// Given a list of source node IDs (strings), find all neighbors connected by `edge_type`
        /// in the specified `direction`.
        pub fn traverse(&self, sources: &[String], edge_type: Option<&str>, direction: Direction) -> Vec<String> {
            let type_filter = edge_type.and_then(|t| self.edge_type_map.get(t).copied());
            
            let mut result_ids: Vec<u32> = Vec::with_capacity(sources.len() * 2);
            
            let adjacency = match direction {
                Direction::Outgoing => &self.outgoing,
                Direction::Incoming => &self.incoming,
            };

            for src_str in sources {
                // If source node doesn't exist in our index, skip it
                if let Some(src_id) = self.node_interner.lookup_id(src_str) {
                    // Check if node is deleted
                    if self.tombstones.get(src_id as usize).as_deref() == Some(&true) {
                        continue;
                    }

                    if let Some(edges) = adjacency.get(src_id as usize) {
                        for &(target, type_id) in edges {
                            // Apply edge type filter if present
                            if let Some(req_type) = type_filter {
                                if req_type != type_id {
                                    continue;
                                }
                            }
                            // Check if target is deleted
                            if self.tombstones.get(target as usize).as_deref() == Some(&true) {
                                continue;
                            }
                            result_ids.push(target);
                        }
                    }
                }
            }

            // Deduplicate results
            result_ids.sort_unstable();
            result_ids.dedup();

            // Convert back to strings
            result_ids
                .into_iter()
                .filter_map(|id| self.node_interner.lookup(id).map(|s| s.to_string()))
                .collect()
        }

        pub fn node_count(&self) -> usize {
            self.node_interner.len()
        }

        /// Serializes the entire graph topology to a binary file.
        pub fn save_to_file(&self, path: &str) -> Result<(), String> {
            let file = File::create(path).map_err(|e| e.to_string())?;
            let writer = BufWriter::new(file);
            bincode::serialize_into(writer, self).map_err(|e| e.to_string())?;
            Ok(())
        }

        /// Deserializes the graph topology from a binary file.
        pub fn load_from_file(path: &str) -> Result<Self, String> {
            let file = File::open(path).map_err(|e| e.to_string())?;
            let reader = BufReader::new(file);
            bincode::deserialize_from(reader).map_err(|e| e.to_string())
        }
    }
  packages/native/src/lib.rs: |-
    #![deny(clippy::all)]

    use napi::bindgen_prelude::*;
    use napi_derive::napi;
    use quack_core::{GraphIndex, Direction};
    use arrow::ipc::reader::StreamReader;
    use std::io::Cursor;

    #[napi]
    pub struct NativeGraph {
        inner: GraphIndex,
    }

    #[napi]
    impl NativeGraph {
        #[napi(constructor)]
        pub fn new() -> Self {
            Self {
                inner: GraphIndex::new(),
            }
        }

        #[napi]
        pub fn add_node(&mut self, id: String) {
            self.inner.get_or_create_node(&id);
        }

        /// Hydrates the graph from an Arrow IPC stream (Buffer).
        /// Zero-copy (mostly) data transfer from DuckDB.
        #[napi]
        pub fn load_arrow_ipc(&mut self, buffer: Buffer) -> napi::Result<()> {
            let cursor = Cursor::new(buffer.as_ref());
            let reader = StreamReader::try_new(cursor, None).map_err(|e| napi::Error::from_reason(e.to_string()))?;

            for batch in reader {
                let batch = batch.map_err(|e| napi::Error::from_reason(e.to_string()))?;
                self.inner.add_arrow_batch(&batch).map_err(|e| napi::Error::from_reason(e))?;
            }
            Ok(())
        }

        #[napi]
        pub fn add_edge(&mut self, source: String, target: String, edge_type: String) {
            self.inner.add_edge(&source, &target, &edge_type);
        }

        #[napi]
        pub fn remove_node(&mut self, id: String) {
            self.inner.remove_node(&id);
        }

        #[napi]
        pub fn remove_edge(&mut self, source: String, target: String, edge_type: String) {
            self.inner.remove_edge(&source, &target, &edge_type);
        }

        /// Performs a single-hop traversal (bfs-step).
        /// Returns unique neighbor IDs.
        #[napi]
        pub fn traverse(&self, sources: Vec<String>, edge_type: Option<String>, direction: Option<String>) -> Vec<String> {
            let dir = match direction.as_deref() {
                Some("in") | Some("IN") => Direction::Incoming,
                _ => Direction::Outgoing,
            };
            self.inner.traverse(&sources, edge_type.as_deref(), dir)
        }

        /// Returns the number of nodes in the interned index.
        /// Useful for debugging hydration.
        #[napi(getter)]
        pub fn node_count(&self) -> u32 {
            // We cast to u32 because exposing usize to JS can be finicky depending on napi version,
            // though napi usually handles numbers well. Safe for V1.
            self.inner.node_count() as u32
        }

        #[napi(getter)]
        pub fn edge_count(&self) -> u32 {
            self.inner.edge_count() as u32
        }

        #[napi]
        pub fn save_snapshot(&self, path: String) -> napi::Result<()> {
            self.inner.save_to_file(&path).map_err(|e| napi::Error::from_reason(e))
        }

        #[napi]
        pub fn load_snapshot(&mut self, path: String) -> napi::Result<()> {
            let loaded = GraphIndex::load_from_file(&path).map_err(|e| napi::Error::from_reason(e))?;
            self.inner = loaded;
            Ok(())
        }
    }
  packages/quack-graph/src/graph.ts: |-
    import { NativeGraph } from '@quackgraph/native';
    import { DuckDBManager } from './db';
    import { SchemaManager } from './schema';
    import { QueryBuilder } from './query';

    export class QuackGraph {
      db: DuckDBManager;
      schema: SchemaManager;
      native: NativeGraph;
      
      // Context for the current instance (Time Travel)
      context: {
        asOf?: Date;
        topologySnapshot?: string;
      } = {};

      constructor(path: string = ':memory:', options: { asOf?: Date, topologySnapshot?: string } = {}) {
        this.db = new DuckDBManager(path);
        this.schema = new SchemaManager(this.db);
        this.native = new NativeGraph();
        this.context.asOf = options.asOf;
        this.context.topologySnapshot = options.topologySnapshot;
      }

      async init() {
        await this.db.init();
        
        // Load Extensions
        try {
          await this.db.execute("INSTALL vss; LOAD vss;");
        } catch (e) {
          console.warn("QuackGraph: Failed to load 'vss' extension. Vector search will be disabled.", e);
        }
        
        await this.schema.ensureSchema();
        
        // If we are in time-travel mode, we might skip hydration or hydrate a snapshot (Advanced).
        // For V1, we always hydrate "Current Active" topology.

        // Check for Topology Snapshot
        if (this.context.topologySnapshot) {
          try {
            // Try loading from disk
            this.native.loadSnapshot(this.context.topologySnapshot);
            // If successful, skip hydration
            return;
          } catch (e) {
            console.warn(`QuackGraph: Failed to load snapshot '${this.context.topologySnapshot}'. Falling back to full hydration.`, e);
          }
        }

        try {
          await this.hydrate();
        } catch (e) {
          console.error("Failed to hydrate graph topology from disk:", e);
          // We don't throw here to allow partial functionality (metadata queries) if needed,
          // but usually this is fatal for graph operations.
          throw e;
        }
      }

      /**
       * Hydrates the in-memory Rust graph from the persistent DuckDB storage.
       * This is critical for the "Split-Brain" architecture.
       */
      async hydrate() {
        // Zero-Copy Arrow IPC
        // 'valid_to IS NULL' ensures we only load currently active edges.
        try {
          const ipcBuffer = await this.db.queryArrow(
            "SELECT source, target, type FROM edges WHERE valid_to IS NULL"
          );
        
          if (ipcBuffer && ipcBuffer.length > 0) {
             // Napi-rs expects a Buffer or equivalent
             // Buffer.from is zero-copy in Node for Uint8Array usually, or cheap copy
             // We cast to any to satisfy the generated TS definitions which might expect Buffer
             this.native.loadArrowIpc(ipcBuffer as any);
          }
        } catch (e: any) {
          throw new Error(`Hydration Error: ${e.message}`);
        }
      }

      asOf(date: Date): QuackGraph {
        // Return a shallow copy with new context
        const g = new QuackGraph(this.db['path'], { asOf: date });
        // Share the same DB connection and Native index (assuming topology is shared/latest)
        g.db = this.db;
        g.schema = this.schema;
        g.native = this.native;
        return g;
      }

      // --- Write Operations (Write-Through) ---

      async addNode(id: string, labels: string[], props: Record<string, any> = {}) {
        // 1. Write to Disk (Source of Truth)
        await this.schema.writeNode(id, labels, props);
        // 2. Write to RAM (Cache)
        this.native.addNode(id);
      }

      async addEdge(source: string, target: string, type: string, props: Record<string, any> = {}) {
        // 1. Write to Disk
        await this.schema.writeEdge(source, target, type, props);
        // 2. Write to RAM
        this.native.addEdge(source, target, type);
      }

      async deleteNode(id: string) {
        // 1. Write to Disk (Soft Delete)
        await this.schema.deleteNode(id);
        // 2. Write to RAM (Tombstone)
        this.native.removeNode(id);
      }

      async deleteEdge(source: string, target: string, type: string) {
        // 1. Write to Disk (Soft Delete)
        await this.schema.deleteEdge(source, target, type);
        // 2. Write to RAM (Remove)
        this.native.removeEdge(source, target, type);
      }

      // --- Optimization & Maintenance ---

      get optimize() {
        return {
          promoteProperty: async (label: string, property: string, type: string) => {
            await this.schema.promoteNodeProperty(label, property, type);
          },
          saveTopologySnapshot: (path: string) => {
            this.native.saveSnapshot(path);
          }
        };
      }

      // --- Read Operations ---

      match(labels: string[]): QueryBuilder {
        return new QueryBuilder(this, labels);
      }
    }
  packages/quack-graph/src/query.ts: |-
    import { QuackGraph } from './graph';

    type TraversalStep = {
      type: 'out' | 'in';
      edge: string;
    };

    export class QueryBuilder {
      private graph: QuackGraph;
      private startLabels: string[];
      private endLabels: string[] = [];

      // Bottom Bun Filters (Initial selection)
      private initialFilters: Record<string, any> = {};
      private vectorSearch: { vector: number[]; limit: number } | null = null;

      // The Meat (Traversal)
      private traversals: TraversalStep[] = [];

      // Top Bun Filters (Final selection)
      private terminalFilters: Record<string, any> = {};

      constructor(graph: QuackGraph, labels: string[]) {
        this.graph = graph;
        this.startLabels = labels;
      }

      /**
       * Filter nodes by properties.
       * If called before traversal, applies to Start Nodes.
       * If called after traversal, applies to End Nodes.
       */
      where(criteria: Record<string, any>): this {
        if (this.traversals.length === 0) {
          this.initialFilters = { ...this.initialFilters, ...criteria };
        } else {
          this.terminalFilters = { ...this.terminalFilters, ...criteria };
        }
        return this;
      }

      /**
       * Perform a Vector Similarity Search (HNSW).
       * This effectively sorts the start nodes by distance to the query vector.
       */
      nearText(vector: number[], options: { limit?: number } = {}): this {
        this.vectorSearch = { 
          vector, 
          limit: options.limit || 10 
        };
        return this;
      }

      out(edgeType: string): this {
        this.traversals.push({ type: 'out', edge: edgeType });
        return this;
      }

      /**
       * Filter the nodes at the end of the traversal by label.
       */
      node(labels: string[]): this {
        this.endLabels = labels;
        return this;
      }

      /**
       * Helper to construct the temporal validity clause
       */
      private getTemporalClause(tableAlias: string = ''): string {
        const prefix = tableAlias ? `${tableAlias}.` : '';
        if (this.graph.context.asOf) {
          // Time Travel: valid_from <= T AND (valid_to > T OR valid_to IS NULL)
          // Interpolate strict ISO string
          const iso = this.graph.context.asOf.toISOString();
          // DuckDB TIMESTAMP comparison works with ISO strings
          return `(${prefix}valid_from <= '${iso}' AND (${prefix}valid_to > '${iso}' OR ${prefix}valid_to IS NULL))`;
        }
        // Default: Current valid records (valid_to is NULL)
        return `${prefix}valid_to IS NULL`;
      }

      async select<T = any>(mapper?: (node: any) => T): Promise<T[]> {
        // --- Step 1: DuckDB Filter (Bottom Bun) ---
        // Objective: Get a list of "Active" Node IDs to feed into the graph.

        let query = `SELECT id FROM nodes`;
        const params: any[] = [];
        const conditions: string[] = [];

        // 1.a Temporal Filter
        conditions.push(this.getTemporalClause());

        // 1.b Label Filter
        if (this.startLabels.length > 0) {
          // Check if ANY of the labels match. For V1 we check the first one or intersection.
          conditions.push(`list_contains(labels, ?)`);
          params.push(this.startLabels[0]);
        }

        // 1.c Property Filter
        for (const [key, value] of Object.entries(this.initialFilters)) {
          conditions.push(`json_extract(properties, '$.${key}') = ?`);
          params.push(value);
        }

        // 1.d Vector Search (Order By Distance)
        let orderBy = '';
        let limit = '';
        if (this.vectorSearch) {
          // Requires: array_distance(embedding, [1,2,3])
          // DuckDB VSS extension syntax
          const vectorStr = `[${this.vectorSearch.vector.join(',')}]`; // Inline vector for V1
          orderBy = `ORDER BY array_distance(embedding, ${vectorStr}::FLOAT[${this.vectorSearch.vector.length}])`;
          limit = `LIMIT ${this.vectorSearch.limit}`;
        }

        if (conditions.length > 0) {
          query += ` WHERE ${conditions.join(' AND ')}`;
        }

        query += ` ${orderBy} ${limit}`;

        const startRows = await this.graph.db.query(query, params);
        let currentIds: string[] = startRows.map(row => row.id);

        if (currentIds.length === 0) return [];

        // --- Step 2: Rust Traversal (The Meat) ---
        // Note: Rust Graph Index is currently "Latest Topology Only". 
        // Time Travel on topology requires checking edge validity during traversal (V2).
        // For V1, we accept that traversal is instant/current, but properties are historical.

        for (const step of this.traversals) {
          if (currentIds.length === 0) break;
          // step.type is 'out' | 'in'
          // native.traverse(ids, edgeType, direction)
          currentIds = this.graph.native.traverse(currentIds, step.edge, step.type);
        }

        // --- Step 3: DuckDB Hydration (Top Bun) ---
        // Objective: Fetch full properties for the resulting IDs, applying terminal filters.

        if (currentIds.length === 0) return [];

        const finalConditions: string[] = [];
        const finalParams: any[] = [];

        // 3.0 Label Filter (for End Nodes)
        if (this.endLabels.length > 0) {
          finalConditions.push(`list_contains(labels, ?)`);
          finalParams.push(this.endLabels[0]);
        }

        // 3.a IDs match
        // We can't use parameters for IN clause effectively with dynamic length in all drivers.
        // Constructing placeholders.
        const placeholders = currentIds.map(() => '?').join(',');
        finalConditions.push(`id IN (${placeholders})`);
        finalParams.push(...currentIds);

        // 3.b Temporal Validity
        finalConditions.push(this.getTemporalClause());

        // 3.c Terminal Property Filters
        for (const [key, value] of Object.entries(this.terminalFilters)) {
          finalConditions.push(`json_extract(properties, '$.${key}') = ?`);
          finalParams.push(value);
        }

        const finalSql = `SELECT * FROM nodes WHERE ${finalConditions.join(' AND ')}`;
        const results = await this.graph.db.query(finalSql, finalParams);

        return results.map(r => {
          let props = r.properties;
          if (typeof props === 'string') {
            try { props = JSON.parse(props); } catch {}
          }
          const node = {
            id: r.id,
            labels: r.labels,
            ...props
          };
          return mapper ? mapper(node) : node;
        });
      }
    }
  packages/quack-graph/src/db.ts: >-
    import { Database } from 'duckdb-async';


    // Interface for operations that can be performed within a transaction or
    globally

    export interface DbExecutor {
      execute(sql: string, params?: any[]): Promise<void>;
      query(sql: string, params?: any[]): Promise<any[]>;
    }


    export class DuckDBManager implements DbExecutor {
      private db: Database | null = null;
      private path: string;

      constructor(path: string = ':memory:') {
        this.path = path;
      }

      async init() {
        if (!this.db) {
          this.db = await Database.create(this.path);
        }
      }

      getDb(): Database {
        if (!this.db) {
          throw new Error('Database not initialized. Call init() first.');
        }
        return this.db;
      }

      async execute(sql: string, params: any[] = []): Promise<void> {
        const db = this.getDb();
        await db.run(sql, params);
      }

      async query(sql: string, params: any[] = []): Promise<any[]> {
        const db = this.getDb();
        return await db.all(sql, params);
      }

      /**
       * Executes a callback within a transaction using a dedicated connection.
       * This guarantees that all operations inside the callback share the same ACID scope.
       */
      async transaction<T>(callback: (executor: DbExecutor) => Promise<T>): Promise<T> {
        const db = this.getDb();
        const conn = await db.connect();
        
        // Create a transaction-bound executor wrapper
        const txExecutor: DbExecutor = {
          execute: async (sql: string, params: any[] = []) => {
            await conn.run(sql, params);
          },
          query: async (sql: string, params: any[] = []) => {
            return await conn.all(sql, params);
          }
        };

        try {
          await conn.run('BEGIN TRANSACTION');
          const result = await callback(txExecutor);
          await conn.run('COMMIT');
          return result;
        } catch (e) {
          try {
            await conn.run('ROLLBACK');
          } catch (rollbackError) {
            console.error('Failed to rollback transaction:', rollbackError);
          }
          throw e;
        } finally {
          // Best effort close
          if (conn && typeof (conn as any).close === 'function') {
            (conn as any).close();
          }
        }
      }

      /**
       * Executes a query and returns the raw Apache Arrow IPC Buffer.
       * Used for high-speed hydration.
       */
      async queryArrow(sql: string, params: any[] = []): Promise<Uint8Array> {
        const db = this.getDb();
        
        return new Promise((resolve, reject) => {
          // Hack: Access underlying node-duckdb connection/database
          // duckdb-async instance holds 'db' property which is the native Database
          const rawDb = (db as any).db || db;

          // Helper to merge multiple Arrow batches if necessary
          const mergeBatches = (batches: Uint8Array[]) => {
            if (batches.length === 0) return new Uint8Array(0);
            if (batches.length === 1) return batches[0];
            const totalLength = batches.reduce((acc, val) => acc + val.length, 0);
            const merged = new Uint8Array(totalLength);
            let offset = 0;
            for (const batch of batches) {
              merged.set(batch, offset);
              offset += batch.length;
            }
            return merged;
          };

          // Try Database.arrowIPCAll (available in newer node-duckdb)
          if (typeof rawDb.arrowIPCAll === 'function') {
            rawDb.arrowIPCAll(sql, params, (err: any, result: any) => {
              if (err) return reject(err);
              // Result is usually Array<Uint8Array> (batches)
              if (Array.isArray(result)) {
                resolve(mergeBatches(result));
              } else {
                resolve(result);
              }
            });
          } else {
             // Fallback: Create a raw connection
             try {
                const rawConn = rawDb.connect();
                if (rawConn && typeof rawConn.arrowIPCAll === 'function') {
                   rawConn.arrowIPCAll(sql, params, (err: any, result: any) => {
                      if (err) return reject(err);
                      if (Array.isArray(result)) {
                        resolve(mergeBatches(result));
                      } else {
                        resolve(result);
                      }
                   });
                } else {
                   reject(new Error("Underlying DuckDB driver does not support arrowIPCAll"));
                }
             } catch(e) {
                reject(e);
             }
          }
        });
      }
    }
approved: true
linesAdded: 56
linesRemoved: 9
linesDifference: 65
gitCommittedAt: '2025-12-02T09:11:01.698Z'
status: committed
id: 14
