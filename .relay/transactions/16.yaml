uuid: 4a3e79b8-3e4b-4811-9f7e-7c156828a1c6
projectId: quackgraph
createdAt: '2025-12-02T09:36:03.852Z'
gitCommitMsg: >-
  fix(core): resolve lifetime issues in arrow batch ingestion

  Replaces the problematic `Box<dyn Fn>` closure in `add_arrow_batch` with an
  explicit `StringArrayWrapper` enum. This fixes lifetime inference errors
  regarding the borrowed string references and improves performance by removing
  dynamic dispatch in the hot loop.
promptSummary: >-
  Fix Rust compilation error E0106 (missing lifetime specifier) in
  `add_arrow_batch` by replacing the closure-based accessor with an enum
  wrapper.
reasoning:
  - >-
    The Rust compilation error `error[E0106]: missing lifetime specifier` occurs
    because we are trying to return a `Box<dyn Fn(...) -> &str>` where the
    returned `&str` reference is derived from a captured variable `arr`.
    Expressing this lifetime relationship in a closure's return type (especially
    boxed trait objects) is notoriously difficult in Rust without complex
    Higher-Rank Trait Bounds (HRTB) or explicit lifetime annotations that
    closures often fail to infer.
  - >-
    Instead of fighting the closure inference, the cleaner and more performant
    solution is to use a lightweight enum wrapper (`StringArrayWrapper`) to
    abstract over `StringArray` (Utf8) and `LargeStringArray` (LargeUtf8). This
    approach avoids virtual function calls per row (`Box<dyn Fn>`) and makes
    lifetimes explicit and easy for the compiler to verify.
  - >-
    I will patch `crates/quack_core/src/topology.rs` to replace the problematic
    closure with this enum-based approach and a simple macro for instantiation.
operations:
  - type: write
    path: crates/quack_core/src/topology.rs
    content: >
      --- crates/quack_core/src/topology.rs

      +++ crates/quack_core/src/topology.rs

      @@ -7,7 +7,7 @@
       use std::io::{BufReader, BufWriter};
       use arrow::record_batch::RecordBatch;
      -use arrow::array::{AsArray, Array, ArrayRef};

      +use arrow::array::{AsArray, Array, ArrayRef, StringArray,
      LargeStringArray};
       use arrow::datatypes::DataType;
       
       /// The core Graph Index.
      @@ -165,33 +165,30 @@
                   return Ok(());
               }
       
      -        // Helper to get string accessors regardless of Utf8 (i32
      offsets) vs LargeUtf8 (i64 offsets)

      -        let get_accessor = |col: &ArrayRef| -> Result<Box<dyn Fn(usize)
      -> &str + '_>, String> {

      -            match col.data_type() {

      -                DataType::Utf8 => {

      -                    let arr = col.as_string::<i32>();

      -                    Ok(Box::new(move |i| arr.value(i)))

      -                },

      -                DataType::LargeUtf8 => {

      -                    let arr = col.as_string::<i64>();

      -                    Ok(Box::new(move |i| arr.value(i)))

      -                },

      -                dt => Err(format!("Unsupported Arrow column type: {:?}.
      Expected Utf8 or LargeUtf8.", dt))

      +        // Wrapper to handle different string array types (Utf8 vs
      LargeUtf8)

      +        enum StringArrayWrapper<'a> {

      +            Small(&'a StringArray),

      +            Large(&'a LargeStringArray),

      +        }

      +

      +        impl<'a> StringArrayWrapper<'a> {

      +            fn value(&self, i: usize) -> &'a str {

      +                match self {

      +                    Self::Small(arr) => arr.value(i),

      +                    Self::Large(arr) => arr.value(i),

      +                }
                   }
      -        };

      +        }
       
      -        let src_fn = get_accessor(batch.column(src_idx))?;

      -        let tgt_fn = get_accessor(batch.column(tgt_idx))?;

      -        let type_fn = get_accessor(batch.column(type_idx))?;

      +        macro_rules! get_wrapper {

      +            ($col:expr, $name:expr) => {

      +                match $col.data_type() {

      +                    DataType::Utf8 =>
      StringArrayWrapper::Small($col.as_string::<i32>()),

      +                    DataType::LargeUtf8 =>
      StringArrayWrapper::Large($col.as_string::<i64>()),

      +                    dt => return Err(format!("{} column: Unsupported type
      {:?}", $name, dt)),

      +                }

      +            }

      +        }

      +

      +        let src_wrapper = get_wrapper!(batch.column(src_idx), "Source");

      +        let tgt_wrapper = get_wrapper!(batch.column(tgt_idx), "Target");

      +        let type_wrapper = get_wrapper!(batch.column(type_idx), "Type");
       
               for i in 0..num_rows {
      -            self.add_edge(src_fn(i), tgt_fn(i), type_fn(i));

      +            self.add_edge(src_wrapper.value(i), tgt_wrapper.value(i),
      type_wrapper.value(i));
               }
               Ok(())
           }
    patchStrategy: standard-diff
snapshot:
  crates/quack_core/src/topology.rs: |-
    use crate::interner::Interner;
    use bitvec::prelude::*;
    use std::collections::HashMap;
    use serde::{Serialize, Deserialize};
    use std::fs::File;
    use std::io::{BufReader, BufWriter};
    use arrow::record_batch::RecordBatch;
    use arrow::array::{AsArray, Array, ArrayRef};
    use arrow::datatypes::DataType;

    /// The core Graph Index.
    /// Stores topology in RAM using integer IDs.
    #[derive(Default, Debug, Serialize, Deserialize)]
    pub struct GraphIndex {
        node_interner: Interner,
        
        // Mapping edge type strings (e.g. "KNOWS") to u8 for compact storage.
        // Limit: 256 edge types per graph in V1.
        edge_type_map: HashMap<String, u8>,
        edge_type_vec: Vec<String>,

        // Forward Graph: Source Node ID -> List of (Target Node ID, Edge Type ID)
        outgoing: Vec<Vec<(u32, u8)>>,
        
        // Reverse Graph: Target Node ID -> List of (Source Node ID, Edge Type ID)
        incoming: Vec<Vec<(u32, u8)>>,

        // Bitmask for soft-deleted nodes.
        // true = deleted (tombstone), false = active.
        tombstones: BitVec,
    }

    pub enum Direction {
        Outgoing,
        Incoming,
    }

    impl GraphIndex {
        pub fn new() -> Self {
            Self {
                node_interner: Interner::new(),
                edge_type_map: HashMap::new(),
                edge_type_vec: Vec::new(),
                outgoing: Vec::new(),
                incoming: Vec::new(),
                tombstones: BitVec::new(),
            }
        }

        /// Compacts internal vectors to minimize memory usage.
        /// Should be called after bulk hydration.
        pub fn compact(&mut self) {
            self.outgoing.shrink_to_fit();
            self.outgoing.iter_mut().for_each(|v| v.shrink_to_fit());
            self.incoming.shrink_to_fit();
            self.incoming.iter_mut().for_each(|v| v.shrink_to_fit());
            self.edge_type_vec.shrink_to_fit();
        }

        /// Resolves or creates an internal u32 ID for a node string.
        /// Resizes internal storage if necessary.
        pub fn get_or_create_node(&mut self, id: &str) -> u32 {
            let internal_id = self.node_interner.intern(id);
            let idx = internal_id as usize;

            // Ensure vectors are large enough to hold this node
            if idx >= self.outgoing.len() {
                let new_len = idx + 1;
                self.outgoing.resize_with(new_len, Vec::new);
                self.incoming.resize_with(new_len, Vec::new);
                // Resize tombstones, filling new slots with false (active)
                self.tombstones.resize(new_len, false);
            }
            internal_id
        }

        /// Marks a node as deleted (soft delete).
        /// Traversals will skip this node.
        pub fn remove_node(&mut self, id: &str) {
            if let Some(u_id) = self.node_interner.lookup_id(id) {
                let idx = u_id as usize;
                if idx < self.tombstones.len() {
                    self.tombstones.set(idx, true);
                }
            }
        }

        /// Returns the total number of edges in the graph.
        pub fn edge_count(&self) -> usize {
            self.outgoing.iter().map(|edges| edges.len()).sum()
        }

        /// Resolves or creates a u8 ID for an edge type string.
        /// Panics if more than 255 edge types are used (V1 constraint).
        pub fn get_or_create_type(&mut self, type_name: &str) -> u8 {
            if let Some(&id) = self.edge_type_map.get(type_name) {
                return id;
            }
            let id = self.edge_type_vec.len();
            if id > 255 {
                panic!("QuackGraph V1 Limit: Max 256 unique edge types supported.");
            }
            let id_u8 = id as u8;
            self.edge_type_vec.push(type_name.to_string());
            self.edge_type_map.insert(type_name.to_string(), id_u8);
            id_u8
        }

        /// Adds an edge to the graph. 
        /// Idempotent: Does not add duplicate edges if they already exist.
        pub fn add_edge(&mut self, source: &str, target: &str, edge_type: &str) {
            let u_src = self.get_or_create_node(source);
            let u_tgt = self.get_or_create_node(target);
            let u_type = self.get_or_create_type(edge_type);

            // Add to forward index (Idempotent)
            let out_vec = &mut self.outgoing[u_src as usize];
            if !out_vec.contains(&(u_tgt, u_type)) {
                out_vec.push((u_tgt, u_type));
            }
            
            // Add to reverse index (Idempotent)
            let in_vec = &mut self.incoming[u_tgt as usize];
            if !in_vec.contains(&(u_src, u_type)) {
                in_vec.push((u_src, u_type));
            }

            // Ensure nodes are not tombstoned if they are being re-added/linked
            if self.tombstones.get(u_src as usize).as_deref() == Some(&true) {
                self.tombstones.set(u_src as usize, false);
            }
            if self.tombstones.get(u_tgt as usize).as_deref() == Some(&true) {
                self.tombstones.set(u_tgt as usize, false);
            }
        }

        /// Removes a specific edge from the graph.
        /// Uses swap_remove for O(1) removal, order is not preserved.
        pub fn remove_edge(&mut self, source: &str, target: &str, edge_type: &str) {
            // We only proceed if all entities exist in our interner/maps
            if let (Some(u_src), Some(u_tgt), Some(u_type)) = (
                self.node_interner.lookup_id(source),
                self.node_interner.lookup_id(target),
                self.edge_type_map.get(edge_type).copied(),
            ) {
                // Remove from outgoing
                if let Some(edges) = self.outgoing.get_mut(u_src as usize) {
                    if let Some(pos) = edges.iter().position(|x| *x == (u_tgt, u_type)) {
                        edges.swap_remove(pos);
                    }
                }
                // Remove from incoming
                if let Some(edges) = self.incoming.get_mut(u_tgt as usize) {
                    if let Some(pos) = edges.iter().position(|x| *x == (u_src, u_type)) {
                        edges.swap_remove(pos);
                    }
                }
            }
        }

        /// Ingests an Apache Arrow RecordBatch directly.
        /// Expected Schema: Columns named "source", "target", "type" (case-insensitive or exact).
        pub fn add_arrow_batch(&mut self, batch: &RecordBatch) -> Result<(), String> {
            let schema = batch.schema();
            
            // Resolve column indices by name for robustness (Case-Insensitive)
            let find_col = |name: &str| -> Result<usize, String> {
                schema.fields().iter().position(|f| f.name().eq_ignore_ascii_case(name))
                    .ok_or_else(|| format!("Column '{}' not found in Arrow Batch. Available: {:?}", name, schema.fields().iter().map(|f| f.name()).collect::<Vec<_>>()))
            };

            let src_idx = find_col("source")?;
            let tgt_idx = find_col("target")?;
            let type_idx = find_col("type")?;

            let num_rows = batch.num_rows();
            if num_rows == 0 {
                return Ok(());
            }

            // Helper to get string accessors regardless of Utf8 (i32 offsets) vs LargeUtf8 (i64 offsets)
            let get_accessor = |col: &ArrayRef| -> Result<Box<dyn Fn(usize) -> &str + '_>, String> {
                match col.data_type() {
                    DataType::Utf8 => {
                        let arr = col.as_string::<i32>();
                        Ok(Box::new(move |i| arr.value(i)))
                    },
                    DataType::LargeUtf8 => {
                        let arr = col.as_string::<i64>();
                        Ok(Box::new(move |i| arr.value(i)))
                    },
                    dt => Err(format!("Unsupported Arrow column type: {:?}. Expected Utf8 or LargeUtf8.", dt))
                }
            };

            let src_fn = get_accessor(batch.column(src_idx))?;
            let tgt_fn = get_accessor(batch.column(tgt_idx))?;
            let type_fn = get_accessor(batch.column(type_idx))?;

            for i in 0..num_rows {
                self.add_edge(src_fn(i), tgt_fn(i), type_fn(i));
            }
            Ok(())
        }

        /// Generic traversal step (Bidirectional).
        /// Given a list of source node IDs (strings), find all neighbors connected by `edge_type`
        /// in the specified `direction`.
        pub fn traverse(&self, sources: &[String], edge_type: Option<&str>, direction: Direction) -> Vec<String> {
            let type_filter = edge_type.and_then(|t| self.edge_type_map.get(t).copied());
            
            let mut result_ids: Vec<u32> = Vec::with_capacity(sources.len() * 2);
            
            let adjacency = match direction {
                Direction::Outgoing => &self.outgoing,
                Direction::Incoming => &self.incoming,
            };

            for src_str in sources {
                // If source node doesn't exist in our index, skip it
                if let Some(src_id) = self.node_interner.lookup_id(src_str) {
                    // Check if node is deleted
                    if self.tombstones.get(src_id as usize).as_deref() == Some(&true) {
                        continue;
                    }

                    if let Some(edges) = adjacency.get(src_id as usize) {
                        for &(target, type_id) in edges {
                            // Apply edge type filter if present
                            if let Some(req_type) = type_filter {
                                if req_type != type_id {
                                    continue;
                                }
                            }
                            // Check if target is deleted
                            if self.tombstones.get(target as usize).as_deref() == Some(&true) {
                                continue;
                            }
                            result_ids.push(target);
                        }
                    }
                }
            }

            // Deduplicate results
            result_ids.sort_unstable();
            result_ids.dedup();

            // Convert back to strings
            result_ids
                .into_iter()
                .filter_map(|id| self.node_interner.lookup(id).map(|s| s.to_string()))
                .collect()
        }

        pub fn node_count(&self) -> usize {
            self.node_interner.len()
        }

        /// Serializes the entire graph topology to a binary file.
        pub fn save_to_file(&self, path: &str) -> Result<(), String> {
            let file = File::create(path).map_err(|e| e.to_string())?;
            let writer = BufWriter::new(file);
            bincode::serialize_into(writer, self).map_err(|e| e.to_string())?;
            Ok(())
        }

        /// Deserializes the graph topology from a binary file.
        pub fn load_from_file(path: &str) -> Result<Self, String> {
            let file = File::open(path).map_err(|e| e.to_string())?;
            let reader = BufReader::new(file);
            bincode::deserialize_from(reader).map_err(|e| e.to_string())
        }
    }
approved: true
linesAdded: 28
linesRemoved: 18
linesDifference: 46
gitCommittedAt: null
status: committed
id: 16
