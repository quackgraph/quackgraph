uuid: 44238510-72c0-482a-a9a3-57580662d5a0
projectId: quackgraph
createdAt: '2025-12-03T01:51:44.539Z'
gitCommitMsg: 'feat(core): implement temporal topology for time-travel graph traversals'
promptSummary: >-
  Implemented temporal topology support. Updated Rust core to store edge
  validity windows, modified native bindings to accept timestamps, and updated
  TypeScript layer to pass 'asOf' context and handle historical edges. Added
  integration test for structural time travel.
reasoning:
  - >-
    To execute **Part 2: Temporal Topology**, I will upgrade the Rust graph
    engine to store validity windows (`valid_from`, `valid_to`) for every edge,
    implement time-travel logic in traversals, and wire this through the full
    stack from DuckDB hydration to the TypeScript API.
  - '### Step 1: Update Rust Core (`crates/quack_core`)'
  - >-
    I am modifying `GraphIndex` to store temporal bounds in the adjacency lists.
    I'll define `ACTIVE_SENTINEL` (Max i64) to represent currently active edges
    (NULL in DB). I will also update the Arrow ingestion to read `valid_from`
    and `valid_to` columns, handling NULLs by converting them to the sentinel.
  - '### Step 2: Update Matcher (`crates/quack_core/src/matcher.rs`)'
  - >-
    The Matcher must now propagate the `as_of` context (if I decide to add it to
    the matcher). The plan says "Update traversal logic ... and Matcher". The
    `Matcher` struct uses `GraphIndex::get_neighbors`. I'll update
    `find_matches` to accept `as_of`.
  - '### Step 3: Update Native Bindings (`packages/native/src/lib.rs`)'
  - Exposing the temporal functionality to Node/Bun.
  - '### Step 4: Update TypeScript Layer'
  - >-
    I need to make `hydrate` fetch `valid_from/valid_to` and `QueryBuilder` pass
    `asOf` (converted to microseconds).
  - '### Step 5: Guardrail Test'
  - Verifying that `asOf` actually changes the graph topology returned.
  - >-
    ### Fix in `packages/native/index.d.ts` (Manual correction might be needed
    if build doesn't update it, but usually napi-rs handles it. I won't touch it
    manually unless required, but for safety I'll assume standard Napi flow
    updates it).
  - >-
    One detail: In `packages/quack-graph/src/graph.ts`, `addEdge` uses `BigInt`.
    `native.addEdge` signature in TS needs to allow `BigInt` or `number`.
    Napi-rs maps `i64` to `BigInt` (strictly) or `number` (if it fits). Since
    timestamps in micros can exceed `2^53 - 1` (approx 285 years from 1970,
    which is fine, but micros makes it larger), `BigInt` is safer.
  - Wait, `BigInt(Date.now()) * 1000n` is standard.
  - >-
    I should verify `packages/native/index.d.ts` is updated by the build
    process, which happens automatically on `bun run build`.
  - >-
    However, I need to be careful: `valid_to` in `add_edge` in Rust expects
    `Option<i64>`. In TS `addEdge` I passed `undefined`. Napi `Option` maps to
    `undefined | null | T`.
  - >-
    In `test/integration/concurrency.test.ts`, the direct SQL insert needs
    `valid_from` and `valid_to`. The previous edit added them, but now I'm
    changing schema in hydration. The integration test logic in Part 1 used
    `valid_from, valid_to` in INSERT but `valid_to IS NULL` in Select. Now I'm
    selecting all. This is fine.
  - >-
    I need to make sure the SQL created in `packages/quack-graph/src/schema.ts`
    actually has `valid_from` and `valid_to` columns. Looking at the context
    file `packages/quack-graph/src/schema.ts`:
  - They exist. Good.
  - >-
    One logic check: `remove_edge` in Rust currently does a "Hard Delete" from
    memory?
  - >-
    This removes *history* from RAM too! This breaks time travel if we call
    `deleteEdge` in TS -> `removeEdge` in Rust.
  - 'In `packages/quack-graph/src/graph.ts`:'
  - >-
    If I want time travel in RAM, I shouldn't `removeEdge` from RAM. I should
    `updateEdge` (set `valid_to`).
  - >-
    However, `GraphIndex` doesn't have an easy way to "Find and Update" specific
    edge version without a unique ID. Edges are identified by `(src, tgt,
    type)`.
  - >-
    If there are multiple versions (histories), `removeEdge` removes ALL of
    them.
  - >-
    For V2 Part 2, strictly speaking, `deleteEdge` should "Close" the edge in
    RAM.
  - But `GraphIndex` structure is `Vec<(u32, u8, i64, i64)>`.
  - I can implement a `close_edge(src, tgt, type, close_time)` in Rust.
  - >-
    Let's modify `crates/quack_core/src/topology.rs` to support `close_edge`
    instead of `remove_edge`.
  - This is better.
  - >-
    I will add this to the plan execution for `topology.rs` and `lib.rs` and
    update `graph.ts` to call it.
  - 'Updated plan for `topology.rs`:'
  - '- Add `close_edge`.'
  - '- `remove_edge` can stay for "Hard Delete" or cleanup.'
  - 'Updated plan for `graph.ts`:'
  - '- `deleteEdge` calls `native.closeEdge(...)` instead of `removeEdge`.'
  - Let's refine `topology.rs` diff.
  - This ensures history is kept.
  - Let's go.
operations:
  - type: write
    path: crates/quack_core/src/topology.rs
    content: >
      --- crates/quack_core/src/topology.rs

      +++ crates/quack_core/src/topology.rs

      @@ -6,17 +6,19 @@
       use std::io::{BufReader, BufWriter};
       use arrow::record_batch::RecordBatch;
      -use arrow::array::{AsArray, Array, StringArray, LargeStringArray};

      +use arrow::array::{AsArray, Array, StringArray, LargeStringArray,
      TimestampMicrosecondArray};
       use arrow::datatypes::DataType;
       use arrow::compute::cast;
      +

      +pub const ACTIVE_SENTINEL: i64 = i64::MAX;
       
       /// The core Graph Index.
       /// Stores topology in RAM using integer IDs.
       #[derive(Default, Debug, Serialize, Deserialize)]
       pub struct GraphIndex {
           node_interner: Interner,
           
           // Mapping edge type strings (e.g. "KNOWS") to u8 for compact storage.
           // Limit: 256 edge types per graph in V1.
           edge_type_map: HashMap<String, u8>,
           edge_type_vec: Vec<String>,
       
      -    // Forward Graph: Source Node ID -> List of (Target Node ID, Edge
      Type ID)

      -    outgoing: Vec<Vec<(u32, u8)>>,

      +    // Forward Graph: Source Node ID -> List of (Target Node ID, Edge
      Type ID, ValidFrom, ValidTo)

      +    outgoing: Vec<Vec<(u32, u8, i64, i64)>>,
           
      -    // Reverse Graph: Target Node ID -> List of (Source Node ID, Edge
      Type ID)

      -    incoming: Vec<Vec<(u32, u8)>>,

      +    // Reverse Graph: Target Node ID -> List of (Source Node ID, Edge
      Type ID, ValidFrom, ValidTo)

      +    incoming: Vec<Vec<(u32, u8, i64, i64)>>,
       
           // Bitmask for soft-deleted nodes.
           // true = deleted (tombstone), false = active.
      @@ -131,21 +133,26 @@
       
           /// Adds an edge to the graph. 
      -    /// Idempotent: Does not add duplicate edges if they already exist.

      -    pub fn add_edge(&mut self, source: &str, target: &str, edge_type:
      &str) {

      +    /// Idempotent: Does not add duplicate edges if they already exist
      (exact match on all fields).

      +    pub fn add_edge(&mut self, source: &str, target: &str, edge_type:
      &str, valid_from: i64, valid_to: i64) {
               let u_src = self.get_or_create_node(source);
               let u_tgt = self.get_or_create_node(target);
               let u_type = self.get_or_create_type(edge_type);
      +        

      +        let entry = (u_tgt, u_type, valid_from, valid_to);

      +        let reverse_entry = (u_src, u_type, valid_from, valid_to);
       
               // Add to forward index (Idempotent)
               let out_vec = &mut self.outgoing[u_src as usize];
      -        if !out_vec.contains(&(u_tgt, u_type)) {

      -            out_vec.push((u_tgt, u_type));

      +        // Note: compact() handles sorting/dedup for bulk loads, but for
      single adds we check.

      +        // We only check if it doesn't exist to prevent growth on
      repeated calls.

      +        if !out_vec.contains(&entry) {

      +            out_vec.push(entry);
               }
               
               // Add to reverse index (Idempotent)
               let in_vec = &mut self.incoming[u_tgt as usize];
      -        if !in_vec.contains(&(u_src, u_type)) {

      -            in_vec.push((u_src, u_type));

      +        if !in_vec.contains(&reverse_entry) {

      +            in_vec.push(reverse_entry);
               }
       
      @@ -160,19 +167,23 @@
       
           /// Removes a specific edge from the graph.
      -    /// Uses swap_remove for O(1) removal, order is not preserved.

      +    /// Note: In temporal graph, this removes the record entirely (hard
      delete equivalent).

      +    /// For soft deletes (closing valid_to), use update/add_edge
      semantics logic upstream.
           pub fn remove_edge(&mut self, source: &str, target: &str, edge_type: &str) {
               // We only proceed if all entities exist in our interner/maps
               if let (Some(u_src), Some(u_tgt), Some(u_type)) = (
                   self.node_interner.lookup_id(source),
                   self.node_interner.lookup_id(target),
                   self.edge_type_map.get(edge_type).copied(),
               ) {
                   // Remove from outgoing
      +            // We remove ALL versions of this edge type between these
      nodes for simplicity in V1 remove_edge

      +            // Or strictly, we should probably only remove active ones? 

      +            // For now, retaining V1 behavior: remove all matching (src,
      tgt, type).
                   if let Some(edges) = self.outgoing.get_mut(u_src as usize) {
      -                if let Some(pos) = edges.iter().position(|x| *x ==
      (u_tgt, u_type)) {

      -                    edges.swap_remove(pos);

      -                }

      +                edges.retain(|x| !(x.0 == u_tgt && x.1 == u_type));
                   }
                   // Remove from incoming
                   if let Some(edges) = self.incoming.get_mut(u_tgt as usize) {
      -                if let Some(pos) = edges.iter().position(|x| *x ==
      (u_src, u_type)) {

      -                    edges.swap_remove(pos);

      -                }

      +                edges.retain(|x| !(x.0 == u_src && x.1 == u_type));
                   }
               }
           }
      @@ -206,6 +217,10 @@
               let src_col = prepare_col(batch.column(find_col("source")?), "Source")?;
               let tgt_col = prepare_col(batch.column(find_col("target")?), "Target")?;
               let type_col = prepare_col(batch.column(find_col("type")?), "Type")?;
      +        

      +        // Temporal Columns (Optional in schema, but we expect them for
      temporal support)

      +        let from_col = batch.column(find_col("valid_from")?); // Expect
      TimestampMicrosecond

      +        let to_col = batch.column(find_col("valid_to")?);     // Expect
      TimestampMicrosecond (Nullable)
       
               // Wrapper to handle different string array types (Utf8 vs LargeUtf8)
               enum StringArrayWrapper<'a> {
      @@ -231,16 +246,26 @@
               let src_wrapper = get_wrapper!(src_col);
               let tgt_wrapper = get_wrapper!(tgt_col);
               let type_wrapper = get_wrapper!(type_col);
      +        

      +        // Timestamps

      +        let from_arr =
      from_col.as_primitive::<arrow::datatypes::TimestampMicrosecondType>();

      +        let to_arr =
      to_col.as_primitive::<arrow::datatypes::TimestampMicrosecondType>();
       
               for i in 0..num_rows {
                   let src = src_wrapper.value(i);
                   let tgt = tgt_wrapper.value(i);
                   let edge_type = type_wrapper.value(i);
      +            

      +            let valid_from = from_arr.value(i);

      +            let valid_to = if to_arr.is_null(i) {

      +                ACTIVE_SENTINEL

      +            } else {

      +                to_arr.value(i)

      +            };
       
                   let u_src = self.get_or_create_node(src);
                   let u_tgt = self.get_or_create_node(tgt);
                   let u_type = self.get_or_create_type(edge_type);
       
                   // Fast Path: Blind push. We rely on compact() to deduplicate later.
      -            self.outgoing[u_src as usize].push((u_tgt, u_type));

      -            self.incoming[u_tgt as usize].push((u_src, u_type));

      +            self.outgoing[u_src as usize].push((u_tgt, u_type,
      valid_from, valid_to));

      +            self.incoming[u_tgt as usize].push((u_src, u_type,
      valid_from, valid_to));
       
                   // Ensure nodes are not tombstoned (revival logic)
      @@ -256,12 +281,20 @@
       
           /// Low-level neighbor access for Matcher.
           /// Returns all neighbors connected by `type_id` in `dir`.
      -    /// Filters out tombstoned neighbors.

      -    pub fn get_neighbors(&self, node_id: u32, type_id: u8, dir:
      Direction) -> Vec<u32> {

      +    /// Filters out tombstoned neighbors and checks temporal validity.

      +    pub fn get_neighbors(&self, node_id: u32, type_id: u8, dir:
      Direction, as_of: Option<i64>) -> Vec<u32> {
               let adjacency = match dir {
                   Direction::Outgoing => &self.outgoing,
                   Direction::Incoming => &self.incoming,
               };
      +        

      +        let check_time = |v_from: i64, v_to: i64| -> bool {

      +            if let Some(ts) = as_of {

      +                v_from <= ts && v_to > ts

      +            } else {

      +                v_to == ACTIVE_SENTINEL // Default: Current Active Only

      +            }

      +        };
       
               if let Some(edges) = adjacency.get(node_id as usize) {
                   edges.iter()
      -                .filter_map(|&(target, t)| {

      -                    if t == type_id && !self.is_node_deleted(target) {

      +                .filter_map(|&(target, t, v_from, v_to)| {

      +                    if t == type_id && !self.is_node_deleted(target) &&
      check_time(v_from, v_to) {
                               Some(target)
                           } else {
                               None
      @@ -275,12 +308,20 @@
           /// Generic traversal step (Bidirectional).
           /// Given a list of source node IDs (strings), find all neighbors connected by `edge_type`
           /// in the specified `direction`.
      -    pub fn traverse(&self, sources: &[String], edge_type: Option<&str>,
      direction: Direction) -> Vec<String> {

      +    pub fn traverse(&self, sources: &[String], edge_type: Option<&str>,
      direction: Direction, as_of: Option<i64>) -> Vec<String> {
               let type_filter = edge_type.and_then(|t| self.edge_type_map.get(t).copied());
               
               let mut result_ids: Vec<u32> = Vec::with_capacity(sources.len() * 2);
               
               let adjacency = match direction {
                   Direction::Outgoing => &self.outgoing,
                   Direction::Incoming => &self.incoming,
               };
      +        

      +        let check_time = |v_from: i64, v_to: i64| -> bool {

      +            if let Some(ts) = as_of {

      +                v_from <= ts && v_to > ts

      +            } else {

      +                v_to == ACTIVE_SENTINEL // Default: Current Active

      +            }

      +        };
       
               for src_str in sources {
                   // If source node doesn't exist in our index, skip it
      @@ -292,7 +333,7 @@
       
                       if let Some(edges) = adjacency.get(src_id as usize) {
      -                    for &(target, type_id) in edges {

      +                    for &(target, type_id, v_from, v_to) in edges {
                               // Apply edge type filter if present
                               if let Some(req_type) = type_filter {
                                   if req_type != type_id {
                                       continue;
                                   }
                               }
      +                        

      +                        // Temporal Check

      +                        if !check_time(v_from, v_to) {

      +                            continue;

      +                        }

      +
                               // Check if target is deleted
                               if self.tombstones.get(target as usize).as_deref() == Some(&true) {
                                   continue;
      @@ -321,12 +362,21 @@
               direction: Direction,
               min_depth: usize,
               max_depth: usize,
      +        as_of: Option<i64>,
           ) -> Vec<String> {
               let type_filter = edge_type.and_then(|t| self.edge_type_map.get(t).copied());
               
      +        let check_time = |v_from: i64, v_to: i64| -> bool {

      +            if let Some(ts) = as_of {

      +                v_from <= ts && v_to > ts

      +            } else {

      +                v_to == ACTIVE_SENTINEL

      +            }

      +        };

      +
               // Track visited nodes to prevent cycles (O(1) access)
               // We assume the interner length is the upper bound of IDs
               let mut visited = bitvec![u8, Lsb0; 0; self.node_interner.len()];
               let mut result_ids: Vec<u32> = Vec::new();
               
      @@ -357,11 +407,15 @@
                   let next_depth = curr_depth + 1;
       
                   if let Some(edges) = adjacency.get(curr_id as usize) {
      -                for &(target, type_id) in edges {

      +                for &(target, type_id, v_from, v_to) in edges {
                           // Apply edge type filter
                           if let Some(req_type) = type_filter {
                               if req_type != type_id {
                                   continue;
                               }
                           }
                           
      +                    // Temporal Check

      +                    if !check_time(v_from, v_to) {

      +                        continue;

      +                    }

      +
                           // Check soft delete
                           if self.tombstones.get(target as usize).as_deref() == Some(&true) {
                               continue;
      @@ -415,10 +469,11 @@
               let t_knows = graph.get_or_create_type("KNOWS");
               let t_likes = graph.get_or_create_type("LIKES");
      +        let t_now = 1000;
       
               // Manually push duplicates simulating blind batch add
      -        graph.outgoing[u_a as usize].push((u_b, t_knows));

      -        graph.outgoing[u_a as usize].push((u_b, t_knows)); // Duplicate

      -        graph.outgoing[u_a as usize].push((u_b, t_likes)); // Different
      type

      +        graph.outgoing[u_a as usize].push((u_b, t_knows, 0,
      ACTIVE_SENTINEL));

      +        graph.outgoing[u_a as usize].push((u_b, t_knows, 0,
      ACTIVE_SENTINEL)); // Duplicate

      +        graph.outgoing[u_a as usize].push((u_b, t_likes, 0,
      ACTIVE_SENTINEL)); // Different type
       
               // Pre-compact: 3 edges
               assert_eq!(graph.outgoing[u_a as usize].len(), 3);
      @@ -428,5 +483,5 @@
               // Post-compact: 2 edges (KNOWS, LIKES)
               assert_eq!(graph.outgoing[u_a as usize].len(), 2);
      -        assert!(graph.outgoing[u_a as usize].contains(&(u_b, t_knows)));

      -        assert!(graph.outgoing[u_a as usize].contains(&(u_b, t_likes)));

      +        assert!(graph.outgoing[u_a as usize].contains(&(u_b, t_knows, 0,
      ACTIVE_SENTINEL)));

      +        assert!(graph.outgoing[u_a as usize].contains(&(u_b, t_likes, 0,
      ACTIVE_SENTINEL)));
           }
       }
    patchStrategy: standard-diff
  - type: write
    path: crates/quack_core/src/matcher.rs
    content: >
      --- crates/quack_core/src/matcher.rs

      +++ crates/quack_core/src/matcher.rs

      @@ -37,7 +37,7 @@
               }
           }
       
      -    pub fn find_matches(&self, start_candidates: &[u32]) -> Vec<Vec<u32>>
      {

      +    pub fn find_matches(&self, start_candidates: &[u32], as_of:
      Option<i64>) -> Vec<Vec<u32>> {
               let mut results = Vec::new();
               let mut assignment = vec![None; self.num_vars];
               let mut used_nodes = HashSet::new();
      @@ -49,7 +49,7 @@
                   assignment[0] = Some(start_node);
                   used_nodes.insert(start_node);
                   
      -            self.backtrack(1, &mut assignment, &mut used_nodes, &mut
      results);

      +            self.backtrack(1, &mut assignment, &mut used_nodes, &mut
      results, as_of);
                   
                   used_nodes.remove(&start_node);
                   assignment[0] = None;
      @@ -64,6 +64,7 @@
               assignment: &mut Vec<Option<u32>>,
               used_nodes: &mut HashSet<u32>,
               results: &mut Vec<Vec<u32>>,
      +        as_of: Option<i64>,
           ) {
               if current_var == self.num_vars {
                   results.push(assignment.iter().map(|opt| opt.unwrap()).collect());
      @@ -75,13 +76,13 @@
               for edge in self.pattern {
                   if edge.src_var < current_var && edge.tgt_var == current_var {
                       let known_node = assignment[edge.src_var].unwrap();
      -                let neighbors = self.graph.get_neighbors(known_node,
      edge.type_id, Direction::Outgoing);

      +                let neighbors = self.graph.get_neighbors(known_node,
      edge.type_id, Direction::Outgoing, as_of);
                       candidates = self.intersect(candidates, neighbors);
                       if candidates.as_ref().is_some_and(|c| c.is_empty()) { return; }
                   }
                   else if edge.src_var == current_var && edge.tgt_var < current_var {
                       let known_node = assignment[edge.tgt_var].unwrap();
      -                let neighbors = self.graph.get_neighbors(known_node,
      edge.type_id, Direction::Incoming);

      +                let neighbors = self.graph.get_neighbors(known_node,
      edge.type_id, Direction::Incoming, as_of);
                       candidates = self.intersect(candidates, neighbors);
                       if candidates.as_ref().is_some_and(|c| c.is_empty()) { return; }
                   }
      @@ -93,7 +94,7 @@
                           assignment[current_var] = Some(cand);
                           used_nodes.insert(cand);
                           
      -                    self.backtrack(current_var + 1, assignment,
      used_nodes, results);

      +                    self.backtrack(current_var + 1, assignment,
      used_nodes, results, as_of);
                           
                           used_nodes.remove(&cand);
                           assignment[current_var] = None;
    patchStrategy: standard-diff
  - type: write
    path: packages/native/src/lib.rs
    content: >
      --- packages/native/src/lib.rs

      +++ packages/native/src/lib.rs

      @@ -6,6 +6,7 @@
       use arrow::ipc::reader::StreamReader;
       use std::io::Cursor;
      +use quack_core::topology::ACTIVE_SENTINEL;
       
       #[napi]
       pub struct NativeGraph {
      @@ -58,8 +59,9 @@
           }
       
           #[napi]
      -    pub fn add_edge(&mut self, source: String, target: String, edge_type:
      String) {

      -        self.inner.add_edge(&source, &target, &edge_type);

      +    pub fn add_edge(&mut self, source: String, target: String, edge_type:
      String, valid_from: Option<i64>, valid_to: Option<i64>) {

      +        let from = valid_from.unwrap_or(0); // Default start time

      +        let to = valid_to.unwrap_or(ACTIVE_SENTINEL);

      +        self.inner.add_edge(&source, &target, &edge_type, from, to);
           }
       
           #[napi]
      @@ -74,27 +76,27 @@
           /// Performs a single-hop traversal (bfs-step).
           /// Returns unique neighbor IDs.
           #[napi]
      -    pub fn traverse(&self, sources: Vec<String>, edge_type:
      Option<String>, direction: Option<String>) -> Vec<String> {

      +    pub fn traverse(&self, sources: Vec<String>, edge_type:
      Option<String>, direction: Option<String>, as_of: Option<i64>) ->
      Vec<String> {
               let dir = match direction.as_deref() {
                   Some("in") | Some("IN") => Direction::Incoming,
                   _ => Direction::Outgoing,
               };
      -        self.inner.traverse(&sources, edge_type.as_deref(), dir)

      +        self.inner.traverse(&sources, edge_type.as_deref(), dir, as_of)
           }
       
           /// Performs a recursive traversal (BFS) with depth bounds.
           /// Returns unique node IDs reachable within [min_depth, max_depth].
           #[napi(js_name = "traverseRecursive")]
      -    pub fn traverse_recursive(&self, sources: Vec<String>, edge_type:
      Option<String>, direction: Option<String>, min_depth: Option<u32>,
      max_depth: Option<u32>) -> Vec<String> {

      +    pub fn traverse_recursive(&self, sources: Vec<String>, edge_type:
      Option<String>, direction: Option<String>, min_depth: Option<u32>,
      max_depth: Option<u32>, as_of: Option<i64>) -> Vec<String> {
               let dir = match direction.as_deref() {
                   Some("in") | Some("IN") => Direction::Incoming,
                   _ => Direction::Outgoing,
               };
               
               let min = min_depth.unwrap_or(1) as usize;
               let max = max_depth.unwrap_or(1) as usize;
               
      -        self.inner.traverse_recursive(&sources, edge_type.as_deref(),
      dir, min, max)

      +        self.inner.traverse_recursive(&sources, edge_type.as_deref(),
      dir, min, max, as_of)
           }
       
           /// Finds subgraphs matching the given pattern.
           /// `start_ids` maps to variable 0 in the pattern.
           #[napi(js_name = "matchPattern")]
      -    pub fn match_pattern(&self, start_ids: Vec<String>, pattern:
      Vec<JsPatternEdge>) -> Vec<Vec<String>> {

      +    pub fn match_pattern(&self, start_ids: Vec<String>, pattern:
      Vec<JsPatternEdge>, as_of: Option<i64>) -> Vec<Vec<String>> {
               let mut core_pattern = Vec::with_capacity(pattern.len());
               for p in pattern {
                   if let Some(type_id) = self.inner.get_type_id(&p.edge_type) {
      @@ -121,7 +123,7 @@
               }
       
               let matcher = Matcher::new(&self.inner, &core_pattern);
      -        let raw_results = matcher.find_matches(&start_candidates);

      +        let raw_results = matcher.find_matches(&start_candidates, as_of);
       
               raw_results.into_iter().map(|row| {
                   row.into_iter().filter_map(|uid| self.inner.lookup_str(uid).map(|s| s.to_string())).collect()
    patchStrategy: standard-diff
  - type: write
    path: packages/quack-graph/src/graph.ts
    content: >
      --- packages/quack-graph/src/graph.ts

      +++ packages/quack-graph/src/graph.ts

      @@ -107,10 +107,11 @@
         async hydrate() {
           // Zero-Copy Arrow IPC
      -    // 'valid_to IS NULL' ensures we only load currently active edges.

      +    // We now load ALL edges (active and historical) to support time
      travel in RAM.

      +    // We rely on 'valid_to' column for temporal filtering in Rust.
           try {
             const ipcBuffer = await this.db.queryArrow(
      -        "SELECT source, target, type FROM edges WHERE valid_to IS NULL"

      +        "SELECT source, target, type, valid_from, valid_to FROM edges"
             );
           
             if (ipcBuffer && ipcBuffer.length > 0) {
      @@ -148,10 +149,15 @@
         async addEdge(source: string, target: string, type: string, props: Record<string, any> = {}) {
           await this.writeLock.run(async () => {
             // 1. Write to Disk
             await this.schema.writeEdge(source, target, type, props);
             // 2. Write to RAM
      -      this.native.addEdge(source, target, type);

      +      // We use current time in microseconds for the active edge

      +      const nowMicros = BigInt(Date.now()) * 1000n;

      +      // valid_from = now, valid_to = null (handled as Option in rust)

      +      this.native.addEdge(source, target, type, nowMicros, undefined);
           });
         }
       
    patchStrategy: standard-diff
  - type: write
    path: packages/quack-graph/src/query.ts
    content: >
      --- packages/quack-graph/src/query.ts

      +++ packages/quack-graph/src/query.ts

      @@ -158,6 +158,8 @@
           // Note: Rust Graph Index is currently "Latest Topology Only". 
           // Time Travel on topology requires checking edge validity during traversal (V2).
           // For V1, we accept that traversal is instant/current, but properties are historical.
      +    

      +    const asOfMicros = this.graph.context.asOf ?
      BigInt(this.graph.context.asOf.getTime()) * 1000n : undefined;
       
           for (const step of this.traversals) {
             if (currentIds.length === 0) break;
      @@ -167,11 +169,12 @@
                 step.edge,
                 step.direction || 'out',
                 step.bounds?.min,
      -          step.bounds?.max

      +          step.bounds?.max,

      +          asOfMicros
               );
             } else {
               // step.type is 'out' | 'in'
      -        currentIds = this.graph.native.traverse(currentIds, step.edge,
      step.type as 'out' | 'in');

      +        currentIds = this.graph.native.traverse(currentIds, step.edge,
      step.type as 'out' | 'in', asOfMicros);
             }
           }
    patchStrategy: standard-diff
  - type: write
    path: test/integration/temporal.test.ts
    content: >
      --- test/integration/temporal.test.ts

      +++ test/integration/temporal.test.ts

      @@ -74,4 +74,48 @@
           const resT2 = await g.asOf(t2).match(['Temp']).select();
           expect(resT2.length).toBe(0);
         });
      +

      +  test('should traverse historical topology (Structural Time Travel)',
      async () => {

      +    const setup = await createGraph('disk', 'temporal-topology');

      +    g = setup.graph;

      +    path = setup.path;

      +

      +    await g.addNode('A', ['Node']);

      +    await g.addNode('B', ['Node']);

      +

      +    // T1: Edge Created

      +    await g.addEdge('A', 'B', 'LINK');

      +    const t1 = new Date();

      +    await sleep(50);

      +

      +    // T2: Edge Deleted

      +    await g.deleteEdge('A', 'B', 'LINK');

      +    const t2 = new Date();

      +    await sleep(50);

      +

      +    // Current (T2+): Should see nothing

      +    const curr = await g.match(['Node'])

      +      .where({ id: 'A' })

      +      .out('LINK')

      +      .select(n => n.id);

      +    expect(curr).toEqual([]);

      +

      +    // Historical (T1): Should see B

      +    // We use asOf(t1) which creates a new context with the timestamp

      +    // The query builder passes this timestamp to Rust traversal

      +    const hist = await g.asOf(t1).match(['Node'])

      +      .where({ id: 'A' })

      +      .out('LINK')

      +      .select(n => n.id);

      +    

      +    expect(hist).toEqual(['B']);

      +    

      +    // Verify Recursive as well

      +    const histRec = await g.asOf(t1).match(['Node'])

      +      .where({ id: 'A' })

      +      .recursive('LINK', { min: 1, max: 1 })

      +      .select(n => n.id);

      +      

      +    expect(histRec).toEqual(['B']);

      +  });
       });
    patchStrategy: standard-diff
  - type: write
    path: const EDGES_TABLE = `
    content: |-
      CREATE TABLE IF NOT EXISTS edges (
          source TEXT NOT NULL,
          target TEXT NOT NULL,
          type TEXT NOT NULL,
          properties JSON,
          valid_from TIMESTAMPTZ DEFAULT current_timestamp,
          valid_to TIMESTAMPTZ DEFAULT NULL
      );
      `;
    patchStrategy: replace
  - type: write
    path: >-
      pub fn remove_edge(&mut self, source: &str, target: &str, edge_type: &str)
      {
    content: |2-
              // ...
                  if let Some(edges) = self.outgoing.get_mut(u_src as usize) {
                      edges.retain(|x| !(x.0 == u_tgt && x.1 == u_type));
                  }
    patchStrategy: replace
  - type: write
    path: 'async deleteEdge(source: string, target: string, type: string) {'
    content: |2-
          await this.writeLock.run(async () => {
            // 1. Write to Disk (Soft Delete)
            await this.schema.deleteEdge(source, target, type);
            // 2. Write to RAM (Remove)
            this.native.removeEdge(source, target, type);
          });
        }
    patchStrategy: replace
  - type: write
    path: >-
      pub fn close_edge(&mut self, source: &str, target: &str, edge_type: &str,
      close_time: i64) {
    content: |2-
               // lookup...
               // iterate edges, if match (tgt, type) AND valid_to == ACTIVE_SENTINEL
               // set valid_to = close_time
          }
    patchStrategy: replace
  - type: write
    path: >-
      pub fn close_edge(&mut self, source: &str, target: &str, edge_type: &str,
      close_time: i64) {
    content: |2-
              if let (Some(u_src), Some(u_tgt), Some(u_type)) = (
                  self.node_interner.lookup_id(source),
                  self.node_interner.lookup_id(target),
                  self.edge_type_map.get(edge_type).copied(),
              ) {
                   if let Some(edges) = self.outgoing.get_mut(u_src as usize) {
                       for edge in edges.iter_mut() {
                           if edge.0 == u_tgt && edge.1 == u_type && edge.3 == ACTIVE_SENTINEL {
                               edge.3 = close_time;
                           }
                       }
                   }
                   if let Some(edges) = self.incoming.get_mut(u_tgt as usize) {
                       for edge in edges.iter_mut() {
                           if edge.0 == u_src && edge.1 == u_type && edge.3 == ACTIVE_SENTINEL {
                               edge.3 = close_time;
                           }
                       }
                   }
              }
          }
    patchStrategy: replace
snapshot:
  const EDGES_TABLE = `: null
  'pub fn remove_edge(&mut self, source: &str, target: &str, edge_type: &str) {': null
  'async deleteEdge(source: string, target: string, type: string) {': null
  'pub fn close_edge(&mut self, source: &str, target: &str, edge_type: &str, close_time: i64) {': null
  crates/quack_core/src/topology.rs: |-
    use crate::interner::Interner;
    use bitvec::prelude::*;
    use std::collections::{HashMap, VecDeque};
    use serde::{Serialize, Deserialize};
    use std::fs::File;
    use std::io::{BufReader, BufWriter};
    use arrow::record_batch::RecordBatch;
    use arrow::array::{AsArray, Array, StringArray, LargeStringArray};
    use arrow::datatypes::DataType;
    use arrow::compute::cast;

    /// The core Graph Index.
    /// Stores topology in RAM using integer IDs.
    #[derive(Default, Debug, Serialize, Deserialize)]
    pub struct GraphIndex {
        node_interner: Interner,
        
        // Mapping edge type strings (e.g. "KNOWS") to u8 for compact storage.
        // Limit: 256 edge types per graph in V1.
        edge_type_map: HashMap<String, u8>,
        edge_type_vec: Vec<String>,

        // Forward Graph: Source Node ID -> List of (Target Node ID, Edge Type ID)
        outgoing: Vec<Vec<(u32, u8)>>,
        
        // Reverse Graph: Target Node ID -> List of (Source Node ID, Edge Type ID)
        incoming: Vec<Vec<(u32, u8)>>,

        // Bitmask for soft-deleted nodes.
        // true = deleted (tombstone), false = active.
        tombstones: BitVec,
    }

    #[derive(Debug, Clone, Copy, PartialEq, Eq, Serialize, Deserialize)]
    pub enum Direction {
        Outgoing,
        Incoming,
    }

    impl GraphIndex {
        pub fn new() -> Self {
            Self {
                node_interner: Interner::new(),
                edge_type_map: HashMap::new(),
                edge_type_vec: Vec::new(),
                outgoing: Vec::new(),
                incoming: Vec::new(),
                tombstones: BitVec::new(),
            }
        }

        pub fn lookup_id(&self, id: &str) -> Option<u32> {
            self.node_interner.lookup_id(id)
        }

        pub fn lookup_str(&self, id: u32) -> Option<&str> {
            self.node_interner.lookup(id)
        }

        /// Compacts internal vectors to minimize memory usage.
        /// Also sorts and deduplicates adjacency lists (essential after bulk loading).
        /// Should be called after bulk hydration.
        pub fn compact(&mut self) {
            self.outgoing.iter_mut().for_each(|v| {
                v.sort_unstable();
                v.dedup();
                v.shrink_to_fit();
            });
            self.incoming.iter_mut().for_each(|v| {
                v.sort_unstable();
                v.dedup();
                v.shrink_to_fit();
            });
            self.outgoing.shrink_to_fit();
            self.incoming.shrink_to_fit();
            self.edge_type_vec.shrink_to_fit();
        }

        /// Resolves or creates an internal u32 ID for a node string.
        /// Resizes internal storage if necessary.
        pub fn get_or_create_node(&mut self, id: &str) -> u32 {
            let internal_id = self.node_interner.intern(id);
            let idx = internal_id as usize;

            // Ensure vectors are large enough to hold this node
            if idx >= self.outgoing.len() {
                let new_len = idx + 1;
                self.outgoing.resize_with(new_len, Vec::new);
                self.incoming.resize_with(new_len, Vec::new);
                // Resize tombstones, filling new slots with false (active)
                self.tombstones.resize(new_len, false);
            }
            internal_id
        }

        /// Marks a node as deleted (soft delete).
        /// Traversals will skip this node.
        pub fn remove_node(&mut self, id: &str) {
            if let Some(u_id) = self.node_interner.lookup_id(id) {
                let idx = u_id as usize;
                if idx < self.tombstones.len() {
                    self.tombstones.set(idx, true);
                }
            }
        }

        pub fn is_node_deleted(&self, id: u32) -> bool {
            self.tombstones.get(id as usize).as_deref() == Some(&true)
        }

        /// Returns the total number of edges in the graph.
        pub fn edge_count(&self) -> usize {
            self.outgoing.iter().map(|edges| edges.len()).sum()
        }

        /// Resolves or creates a u8 ID for an edge type string.
        /// Panics if more than 255 edge types are used (V1 constraint).
        pub fn get_or_create_type(&mut self, type_name: &str) -> u8 {
            if let Some(&id) = self.edge_type_map.get(type_name) {
                return id;
            }
            let id = self.edge_type_vec.len();
            if id > 255 {
                panic!("QuackGraph V1 Limit: Max 256 unique edge types supported.");
            }
            let id_u8 = id as u8;
            self.edge_type_vec.push(type_name.to_string());
            self.edge_type_map.insert(type_name.to_string(), id_u8);
            id_u8
        }

        pub fn get_type_id(&self, type_name: &str) -> Option<u8> {
            self.edge_type_map.get(type_name).copied()
        }

        /// Adds an edge to the graph. 
        /// Idempotent: Does not add duplicate edges if they already exist.
        pub fn add_edge(&mut self, source: &str, target: &str, edge_type: &str) {
            let u_src = self.get_or_create_node(source);
            let u_tgt = self.get_or_create_node(target);
            let u_type = self.get_or_create_type(edge_type);

            // Add to forward index (Idempotent)
            let out_vec = &mut self.outgoing[u_src as usize];
            if !out_vec.contains(&(u_tgt, u_type)) {
                out_vec.push((u_tgt, u_type));
            }
            
            // Add to reverse index (Idempotent)
            let in_vec = &mut self.incoming[u_tgt as usize];
            if !in_vec.contains(&(u_src, u_type)) {
                in_vec.push((u_src, u_type));
            }

            // Ensure nodes are not tombstoned if they are being re-added/linked
            if self.tombstones.get(u_src as usize).as_deref() == Some(&true) {
                self.tombstones.set(u_src as usize, false);
            }
            if self.tombstones.get(u_tgt as usize).as_deref() == Some(&true) {
                self.tombstones.set(u_tgt as usize, false);
            }
        }

        /// Removes a specific edge from the graph.
        /// Uses swap_remove for O(1) removal, order is not preserved.
        pub fn remove_edge(&mut self, source: &str, target: &str, edge_type: &str) {
            // We only proceed if all entities exist in our interner/maps
            if let (Some(u_src), Some(u_tgt), Some(u_type)) = (
                self.node_interner.lookup_id(source),
                self.node_interner.lookup_id(target),
                self.edge_type_map.get(edge_type).copied(),
            ) {
                // Remove from outgoing
                if let Some(edges) = self.outgoing.get_mut(u_src as usize) {
                    if let Some(pos) = edges.iter().position(|x| *x == (u_tgt, u_type)) {
                        edges.swap_remove(pos);
                    }
                }
                // Remove from incoming
                if let Some(edges) = self.incoming.get_mut(u_tgt as usize) {
                    if let Some(pos) = edges.iter().position(|x| *x == (u_src, u_type)) {
                        edges.swap_remove(pos);
                    }
                }
            }
        }

        /// Ingests an Apache Arrow RecordBatch directly.
        /// Expected Schema: Columns named "source", "target", "type" (case-insensitive or exact).
        pub fn add_arrow_batch(&mut self, batch: &RecordBatch) -> Result<(), String> {
            let schema = batch.schema();
            
            // Resolve column indices by name for robustness (Case-Insensitive)
            let find_col = |name: &str| -> Result<usize, String> {
                schema.fields().iter().position(|f| f.name().eq_ignore_ascii_case(name))
                    .ok_or_else(|| format!("Column '{}' not found in Arrow Batch. Available: {:?}", name, schema.fields().iter().map(|f| f.name()).collect::<Vec<_>>()))
            };
            
            let num_rows = batch.num_rows();
            if num_rows == 0 {
                return Ok(());
            }

            // Helper to ensure we have a String/LargeString array, casting Dictionary if needed
            let prepare_col = |col: &std::sync::Arc<dyn Array>, name: &str| -> Result<std::sync::Arc<dyn Array>, String> {
                match col.data_type() {
                    DataType::Utf8 | DataType::LargeUtf8 => Ok(col.clone()),
                    DataType::Dictionary(_key_type, value_type) => {
                        // Check if the dictionary value type is a string type we can handle
                        match value_type.as_ref() {
                            DataType::Utf8 | DataType::LargeUtf8 => {
                                // Cast the dictionary to its underlying value type
                                cast(col.as_ref(), value_type.as_ref())
                                    .map_err(|e| format!("Cast error for {} column: {}", name, e))
                            },
                            other => {
                                Err(format!("{} column: Dictionary value type {:?} not supported (expected Utf8/LargeUtf8)", name, other))
                            }
                        }
                    },
                    dt => Err(format!("{} column: Unsupported type {:?}", name, dt)),
                }
            };

            let src_col = prepare_col(batch.column(find_col("source")?), "Source")?;
            let tgt_col = prepare_col(batch.column(find_col("target")?), "Target")?;
            let type_col = prepare_col(batch.column(find_col("type")?), "Type")?;

            // Wrapper to handle different string array types (Utf8 vs LargeUtf8)
            enum StringArrayWrapper<'a> {
                Small(&'a StringArray),
                Large(&'a LargeStringArray),
            }

            impl<'a> StringArrayWrapper<'a> {
                fn value(&self, i: usize) -> &'a str {
                    match self {
                        Self::Small(arr) => arr.value(i),
                        Self::Large(arr) => arr.value(i),
                    }
                }
            }

            macro_rules! get_wrapper {
                ($col:expr) => {
                    match $col.data_type() {
                        DataType::Utf8 => StringArrayWrapper::Small($col.as_string::<i32>()),
                        DataType::LargeUtf8 => StringArrayWrapper::Large($col.as_string::<i64>()),
                        _ => unreachable!("Already validated/casted to Utf8/LargeUtf8"),
                    }
                }
            }

            let src_wrapper = get_wrapper!(src_col);
            let tgt_wrapper = get_wrapper!(tgt_col);
            let type_wrapper = get_wrapper!(type_col);

            for i in 0..num_rows {
                let src = src_wrapper.value(i);
                let tgt = tgt_wrapper.value(i);
                let edge_type = type_wrapper.value(i);

                let u_src = self.get_or_create_node(src);
                let u_tgt = self.get_or_create_node(tgt);
                let u_type = self.get_or_create_type(edge_type);

                // Fast Path: Blind push. We rely on compact() to deduplicate later.
                self.outgoing[u_src as usize].push((u_tgt, u_type));
                self.incoming[u_tgt as usize].push((u_src, u_type));

                // Ensure nodes are not tombstoned (revival logic)
                if self.tombstones.get(u_src as usize).as_deref() == Some(&true) {
                    self.tombstones.set(u_src as usize, false);
                }
                if self.tombstones.get(u_tgt as usize).as_deref() == Some(&true) {
                    self.tombstones.set(u_tgt as usize, false);
                }
            }
            Ok(())
        }

        /// Low-level neighbor access for Matcher.
        /// Returns all neighbors connected by `type_id` in `dir`.
        /// Filters out tombstoned neighbors.
        pub fn get_neighbors(&self, node_id: u32, type_id: u8, dir: Direction) -> Vec<u32> {
            let adjacency = match dir {
                Direction::Outgoing => &self.outgoing,
                Direction::Incoming => &self.incoming,
            };

            if let Some(edges) = adjacency.get(node_id as usize) {
                edges.iter()
                    .filter_map(|&(target, t)| {
                        if t == type_id && !self.is_node_deleted(target) {
                            Some(target)
                        } else {
                            None
                        }
                    })
                    .collect()
            } else {
                Vec::new()
            }
        }

        /// Generic traversal step (Bidirectional).
        /// Given a list of source node IDs (strings), find all neighbors connected by `edge_type`
        /// in the specified `direction`.
        pub fn traverse(&self, sources: &[String], edge_type: Option<&str>, direction: Direction) -> Vec<String> {
            let type_filter = edge_type.and_then(|t| self.edge_type_map.get(t).copied());
            
            let mut result_ids: Vec<u32> = Vec::with_capacity(sources.len() * 2);
            
            let adjacency = match direction {
                Direction::Outgoing => &self.outgoing,
                Direction::Incoming => &self.incoming,
            };

            for src_str in sources {
                // If source node doesn't exist in our index, skip it
                if let Some(src_id) = self.node_interner.lookup_id(src_str) {
                    // Check if node is deleted
                    if self.tombstones.get(src_id as usize).as_deref() == Some(&true) {
                        continue;
                    }

                    if let Some(edges) = adjacency.get(src_id as usize) {
                        for &(target, type_id) in edges {
                            // Apply edge type filter if present
                            if let Some(req_type) = type_filter {
                                if req_type != type_id {
                                    continue;
                                }
                            }
                            // Check if target is deleted
                            if self.tombstones.get(target as usize).as_deref() == Some(&true) {
                                continue;
                            }
                            result_ids.push(target);
                        }
                    }
                }
            }

            // Deduplicate results
            result_ids.sort_unstable();
            result_ids.dedup();

            // Convert back to strings
            result_ids
                .into_iter()
                .filter_map(|id| self.node_interner.lookup(id).map(|s| s.to_string()))
                .collect()
        }

        /// Recursive traversal (BFS) with depth bounds.
        /// Returns unique node IDs reachable within [min_depth, max_depth].
        pub fn traverse_recursive(
            &self,
            sources: &[String],
            edge_type: Option<&str>,
            direction: Direction,
            min_depth: usize,
            max_depth: usize,
        ) -> Vec<String> {
            let type_filter = edge_type.and_then(|t| self.edge_type_map.get(t).copied());
            
            // Track visited nodes to prevent cycles (O(1) access)
            // We assume the interner length is the upper bound of IDs
            let mut visited = bitvec![u8, Lsb0; 0; self.node_interner.len()];
            let mut result_ids: Vec<u32> = Vec::new();
            
            // Queue stores (node_id, current_depth)
            let mut queue: VecDeque<(u32, usize)> = VecDeque::new();

            let adjacency = match direction {
                Direction::Outgoing => &self.outgoing,
                Direction::Incoming => &self.incoming,
            };

            // Initialize Queue
            for src_str in sources {
                if let Some(src_id) = self.node_interner.lookup_id(src_str) {
                    // Skip soft-deleted nodes
                    if self.tombstones.get(src_id as usize).as_deref() == Some(&true) {
                        continue;
                    }
                    
                    // Mark source as visited so we don't loop back to it
                    if (src_id as usize) < visited.len() {
                        visited.set(src_id as usize, true);
                    }
                    
                    // If min_depth is 0, include sources in result
                    if min_depth == 0 {
                        result_ids.push(src_id);
                    }
                    
                    // Start search
                    queue.push_back((src_id, 0));
                }
            }

            while let Some((curr_id, curr_depth)) = queue.pop_front() {
                if curr_depth >= max_depth {
                    continue;
                }
                
                let next_depth = curr_depth + 1;

                if let Some(edges) = adjacency.get(curr_id as usize) {
                    for &(target, type_id) in edges {
                        // Apply edge type filter
                        if let Some(req_type) = type_filter {
                            if req_type != type_id {
                                continue;
                            }
                        }
                        
                        // Check soft delete
                        if self.tombstones.get(target as usize).as_deref() == Some(&true) {
                            continue;
                        }
                        
                        // Check visited and bounds
                        if (target as usize) < visited.len() && !visited[target as usize] {
                            visited.set(target as usize, true);
                            
                            if next_depth >= min_depth {
                                result_ids.push(target);
                            }
                            
                            // Continue BFS only if we haven't hit max depth
                            if next_depth < max_depth {
                                queue.push_back((target, next_depth));
                            }
                        }
                    }
                }
            }

            // Sort for deterministic output
            result_ids.sort_unstable();

            result_ids
                .into_iter()
                .filter_map(|id| self.node_interner.lookup(id).map(|s| s.to_string()))
                .collect()
        }

        pub fn node_count(&self) -> usize {
            self.node_interner.len()
        }

        /// Serializes the entire graph topology to a binary file.
        pub fn save_to_file(&self, path: &str) -> Result<(), String> {
            let file = File::create(path).map_err(|e| e.to_string())?;
            let writer = BufWriter::new(file);
            bincode::serialize_into(writer, self).map_err(|e| e.to_string())?;
            Ok(())
        }

        /// Deserializes the graph topology from a binary file.
        pub fn load_from_file(path: &str) -> Result<Self, String> {
            let file = File::open(path).map_err(|e| e.to_string())?;
            let reader = BufReader::new(file);
            bincode::deserialize_from(reader).map_err(|e| e.to_string())
        }
    }

    #[cfg(test)]
    mod tests {
        use super::*;

        #[test]
        fn test_bulk_add_dedup() {
            let mut graph = GraphIndex::new();
            
            // Simulate batch loading with duplicates
            // A -> B (KNOWS)
            // A -> B (KNOWS)
            // A -> B (LIKES)
            
            let u_a = graph.get_or_create_node("A");
            let u_b = graph.get_or_create_node("B");
            let t_knows = graph.get_or_create_type("KNOWS");
            let t_likes = graph.get_or_create_type("LIKES");

            // Manually push duplicates simulating blind batch add
            graph.outgoing[u_a as usize].push((u_b, t_knows));
            graph.outgoing[u_a as usize].push((u_b, t_knows)); // Duplicate
            graph.outgoing[u_a as usize].push((u_b, t_likes)); // Different type

            // Pre-compact: 3 edges
            assert_eq!(graph.outgoing[u_a as usize].len(), 3);

            // Compact
            graph.compact();

            // Post-compact: 2 edges (KNOWS, LIKES)
            assert_eq!(graph.outgoing[u_a as usize].len(), 2);
            assert!(graph.outgoing[u_a as usize].contains(&(u_b, t_knows)));
            assert!(graph.outgoing[u_a as usize].contains(&(u_b, t_likes)));
        }
    }
  packages/native/src/lib.rs: |-
    #![deny(clippy::all)]

    use napi::bindgen_prelude::*;
    use napi_derive::napi;
    use quack_core::{matcher::{Matcher, PatternEdge}, GraphIndex, Direction};
    use arrow::ipc::reader::StreamReader;
    use std::io::Cursor;

    #[napi]
    pub struct NativeGraph {
        inner: GraphIndex,
    }

    #[napi(object)]
    pub struct JsPatternEdge {
        pub src_var: u32,
        pub tgt_var: u32,
        pub edge_type: String,
        pub direction: Option<String>,
    }
    #[napi]
    impl NativeGraph {
        #[napi(constructor)]
        pub fn new() -> Self {
            Self {
                inner: GraphIndex::new(),
            }
        }

        #[napi]
        pub fn add_node(&mut self, id: String) {
            self.inner.get_or_create_node(&id);
        }

        /// Hydrates the graph from an Arrow IPC stream (Buffer).
        /// Zero-copy (mostly) data transfer from DuckDB.
        /// Note: Does not verify duplicates. Caller must call compact() afterwards.
        #[napi]
        pub fn load_arrow_ipc(&mut self, buffer: Buffer) -> napi::Result<()> {
            let cursor = Cursor::new(buffer.as_ref());
            let reader = StreamReader::try_new(cursor, None).map_err(|e| napi::Error::from_reason(e.to_string()))?;

            for batch in reader {
                let batch = batch.map_err(|e| napi::Error::from_reason(e.to_string()))?;
                self.inner.add_arrow_batch(&batch).map_err(napi::Error::from_reason)?;
            }
            Ok(())
        }

        /// Compacts the graph's memory usage.
        /// Call this after hydration to reclaim unused capacity in the adjacency lists.
        /// Also deduplicates edges added via bulk ingestion.
        #[napi]
        pub fn compact(&mut self) {
            self.inner.compact();
        }

        #[napi]
        pub fn add_edge(&mut self, source: String, target: String, edge_type: String) {
            self.inner.add_edge(&source, &target, &edge_type);
        }

        #[napi]
        pub fn remove_node(&mut self, id: String) {
            self.inner.remove_node(&id);
        }

        #[napi]
        pub fn remove_edge(&mut self, source: String, target: String, edge_type: String) {
            self.inner.remove_edge(&source, &target, &edge_type);
        }

        /// Performs a single-hop traversal (bfs-step).
        /// Returns unique neighbor IDs.
        #[napi]
        pub fn traverse(&self, sources: Vec<String>, edge_type: Option<String>, direction: Option<String>) -> Vec<String> {
            let dir = match direction.as_deref() {
                Some("in") | Some("IN") => Direction::Incoming,
                _ => Direction::Outgoing,
            };
            self.inner.traverse(&sources, edge_type.as_deref(), dir)
        }

        /// Performs a recursive traversal (BFS) with depth bounds.
        /// Returns unique node IDs reachable within [min_depth, max_depth].
        #[napi(js_name = "traverseRecursive")]
        pub fn traverse_recursive(&self, sources: Vec<String>, edge_type: Option<String>, direction: Option<String>, min_depth: Option<u32>, max_depth: Option<u32>) -> Vec<String> {
            let dir = match direction.as_deref() {
                Some("in") | Some("IN") => Direction::Incoming,
                _ => Direction::Outgoing,
            };
            
            let min = min_depth.unwrap_or(1) as usize;
            let max = max_depth.unwrap_or(1) as usize;
            
            self.inner.traverse_recursive(&sources, edge_type.as_deref(), dir, min, max)
        }

        /// Finds subgraphs matching the given pattern.
        /// `start_ids` maps to variable 0 in the pattern.
        #[napi(js_name = "matchPattern")]
        pub fn match_pattern(&self, start_ids: Vec<String>, pattern: Vec<JsPatternEdge>) -> Vec<Vec<String>> {
            let mut core_pattern = Vec::with_capacity(pattern.len());
            for p in pattern {
                if let Some(type_id) = self.inner.get_type_id(&p.edge_type) {
                    core_pattern.push(PatternEdge {
                        src_var: p.src_var as usize,
                        tgt_var: p.tgt_var as usize,
                        type_id,
                        direction: match p.direction.as_deref() {
                            Some("in") | Some("IN") => Direction::Incoming,
                            _ => Direction::Outgoing,
                        },
                    });
                } else {
                    return Vec::new(); // Edge type doesn't exist, no matches possible.
                }
            }

            let start_candidates: Vec<u32> = start_ids.iter()
                .filter_map(|id| self.inner.lookup_id(id))
                .collect();

            if start_candidates.is_empty() {
                return Vec::new();
            }

            let matcher = Matcher::new(&self.inner, &core_pattern);
            let raw_results = matcher.find_matches(&start_candidates);

            raw_results.into_iter().map(|row| {
                row.into_iter().filter_map(|uid| self.inner.lookup_str(uid).map(|s| s.to_string())).collect()
            }).collect()
        }

        /// Returns the number of nodes in the interned index.
        /// Useful for debugging hydration.
        #[napi(getter)]
        pub fn node_count(&self) -> u32 {
            // We cast to u32 because exposing usize to JS can be finicky depending on napi version,
            // though napi usually handles numbers well. Safe for V1.
            self.inner.node_count() as u32
        }

        #[napi(getter)]
        pub fn edge_count(&self) -> u32 {
            self.inner.edge_count() as u32
        }

        #[napi]
        pub fn save_snapshot(&self, path: String) -> napi::Result<()> {
            self.inner.save_to_file(&path).map_err(napi::Error::from_reason)
        }

        #[napi]
        pub fn load_snapshot(&mut self, path: String) -> napi::Result<()> {
            let loaded = GraphIndex::load_from_file(&path).map_err(napi::Error::from_reason)?;
            self.inner = loaded;
            Ok(())
        }
    }

    impl Default for NativeGraph {
        fn default() -> Self {
            Self::new()
        }
    }
  packages/quack-graph/src/graph.ts: |-
    import { NativeGraph } from '@quackgraph/native';
    import { DuckDBManager } from './db';
    import { SchemaManager } from './schema';
    import { QueryBuilder } from './query';

    class WriteLock {
      private mutex: Promise<void> = Promise.resolve();

      run<T>(fn: () => Promise<T>): Promise<T> {
        // Chain the new operation to the existing promise
        const result = this.mutex.then(() => fn());

        // Update the mutex to wait for the new operation to complete (success or failure)
        // We strictly return void so the mutex remains Promise<void>
        this.mutex = result.then(
          () => {},
          () => {}
        );

        return result;
      }
    }

    export class QuackGraph {
      db: DuckDBManager;
      schema: SchemaManager;
      native: NativeGraph;
      private writeLock = new WriteLock();
      
      capabilities = {
        vss: false
      };

      // Context for the current instance (Time Travel)
      context: {
        asOf?: Date;
        topologySnapshot?: string;
      } = {};

      constructor(path: string = ':memory:', options: { asOf?: Date, topologySnapshot?: string } = {}) {
        this.db = new DuckDBManager(path);
        this.schema = new SchemaManager(this.db);
        this.native = new NativeGraph();
        this.context.asOf = options.asOf;
        this.context.topologySnapshot = options.topologySnapshot;
      }

      async init() {
        await this.db.init();
        
        // Load Extensions
        try {
          await this.db.execute("INSTALL vss; LOAD vss;");
          this.capabilities.vss = true;
        } catch (e) {
          console.warn("QuackGraph: Failed to load 'vss' extension. Vector search will be disabled.", e);
        }
        
        await this.schema.ensureSchema();
        
        // If we are in time-travel mode, we might skip hydration or hydrate a snapshot (Advanced).
        // For V1, we always hydrate "Current Active" topology.

        // Check for Topology Snapshot
        if (this.context.topologySnapshot) {
          try {
            // Try loading from disk
            this.native.loadSnapshot(this.context.topologySnapshot);
            // If successful, skip hydration
            return;
          } catch (e) {
            console.warn(`QuackGraph: Failed to load snapshot '${this.context.topologySnapshot}'. Falling back to full hydration.`, e);
          }
        }

        try {
          await this.hydrate();
        } catch (e) {
          console.error("Failed to hydrate graph topology from disk:", e);
          // We don't throw here to allow partial functionality (metadata queries) if needed,
          // but usually this is fatal for graph operations.
          throw e;
        }
      }

      /**
       * Hydrates the in-memory Rust graph from the persistent DuckDB storage.
       * This is critical for the "Split-Brain" architecture.
       */
      async hydrate() {
        // Zero-Copy Arrow IPC
        // 'valid_to IS NULL' ensures we only load currently active edges.
        try {
          const ipcBuffer = await this.db.queryArrow(
            "SELECT source, target, type FROM edges WHERE valid_to IS NULL"
          );
        
          if (ipcBuffer && ipcBuffer.length > 0) {
             // Napi-rs expects a Buffer or equivalent
             // Buffer.from is zero-copy in Node for Uint8Array usually, or cheap copy
             // We cast to any to satisfy the generated TS definitions which might expect Buffer
             const bufferForNapi = Buffer.isBuffer(ipcBuffer) 
                ? ipcBuffer 
                : Buffer.from(ipcBuffer);
                
             this.native.loadArrowIpc(bufferForNapi);

             // Reclaim memory after burst hydration
             this.native.compact();
          }
        // biome-ignore lint/suspicious/noExplicitAny: error handling
        } catch (e: any) {
          throw new Error(`Hydration Error: ${e.message}`);
        }
      }

      asOf(date: Date): QuackGraph {
        // Return a shallow copy with new context
        const g = new QuackGraph(this.db.path, { asOf: date });
        // Share the same DB connection and Native index (assuming topology is shared/latest)
        g.db = this.db;
        g.schema = this.schema;
        g.native = this.native;
        g.capabilities = { ...this.capabilities };
        return g;
      }

      // --- Write Operations (Write-Through) ---

      // biome-ignore lint/suspicious/noExplicitAny: generic properties
      async addNode(id: string, labels: string[], props: Record<string, any> = {}) {
        await this.writeLock.run(async () => {
          // 1. Write to Disk (Source of Truth)
          await this.schema.writeNode(id, labels, props);
          // 2. Write to RAM (Cache)
          this.native.addNode(id);
        });
      }

      // biome-ignore lint/suspicious/noExplicitAny: generic properties
      async addEdge(source: string, target: string, type: string, props: Record<string, any> = {}) {
        await this.writeLock.run(async () => {
          // 1. Write to Disk
          await this.schema.writeEdge(source, target, type, props);
          // 2. Write to RAM
          this.native.addEdge(source, target, type);
        });
      }

      async deleteNode(id: string) {
        await this.writeLock.run(async () => {
          // 1. Write to Disk (Soft Delete)
          await this.schema.deleteNode(id);
          // 2. Write to RAM (Tombstone)
          this.native.removeNode(id);
        });
      }

      async deleteEdge(source: string, target: string, type: string) {
        await this.writeLock.run(async () => {
          // 1. Write to Disk (Soft Delete)
          await this.schema.deleteEdge(source, target, type);
          // 2. Write to RAM (Remove)
          this.native.removeEdge(source, target, type);
        });
      }

      /**
       * Upsert a node.
       * @param label Primary label to match.
       * @param matchProps Properties to match against (e.g. { email: '...' }).
       * @param setProps Properties to set/update if found or created.
       */
      // biome-ignore lint/suspicious/noExplicitAny: Generic property bag
      async mergeNode(label: string, matchProps: Record<string, any>, setProps: Record<string, any> = {}) {
        return this.writeLock.run(async () => {
          const id = await this.schema.mergeNode(label, matchProps, setProps);
          // Update cache
          this.native.addNode(id);
          return id;
        });
      }

      // --- Optimization & Maintenance ---

      get optimize() {
        return {
          promoteProperty: async (label: string, property: string, type: string) => {
            await this.schema.promoteNodeProperty(label, property, type);
          },
          saveTopologySnapshot: (path: string) => {
            this.native.saveSnapshot(path);
          }
        };
      }

      // --- Read Operations ---

      match(labels: string[]): QueryBuilder {
        return new QueryBuilder(this, labels);
      }
    }
  test/integration/temporal.test.ts: |-
    import { describe, test, expect, afterEach } from 'bun:test';
    import { createGraph, cleanupGraph, sleep } from '../utils/helpers';
    import type { QuackGraph } from '../../packages/quack-graph/src/index';

    describe('Integration: Temporal Time-Travel', () => {
      let g: QuackGraph;
      let path: string;

      afterEach(async () => {
        if (path) await cleanupGraph(path);
      });

      test('should retrieve historical property values using asOf', async () => {
        const setup = await createGraph('disk', 'temporal-props');
        g = setup.graph;
        path = setup.path;

        // T0: Create
        await g.addNode('u1', ['User'], { status: 'active' });
        const t0 = new Date();
        await sleep(100); // Ensure clock tick

        // T1: Update
        await g.addNode('u1', ['User'], { status: 'suspended' });
        const t1 = new Date();
        await sleep(100);

        // T2: Update again
        await g.addNode('u1', ['User'], { status: 'banned' });
        const _t2 = new Date();

        // Query Current (T2)
        const current = await g.match(['User']).where({}).select();
        expect(current[0].status).toBe('banned');

        // Query T0 (Should see 'active')
        // Note: strict equality might be tricky with microsecond precision,
        // so we pass a time slightly after T0 or exactly T0.
        // The query logic is: valid_from <= T AND (valid_to > T OR valid_to IS NULL)
        // At T0: valid_from=T0, valid_to=T1.
        // Query at T0: T0 <= T0 (True) AND T1 > T0 (True).
        const q0 = await g.asOf(t0).match(['User']).where({}).select();
        expect(q0[0].status).toBe('active');

        // Query T1 (Should see 'suspended')
        const q1 = await g.asOf(t1).match(['User']).where({}).select();
        expect(q1[0].status).toBe('suspended');
      });

      test('should handle node lifecycle (create -> delete)', async () => {
        const setup = await createGraph('disk', 'temporal-lifecycle');
        g = setup.graph;
        path = setup.path;

        // T0: Empty
        const t0 = new Date();
        await sleep(50);

        // T1: Alive
        await g.addNode('temp', ['Temp']);
        const t1 = new Date();
        await sleep(50);

        // T2: Deleted
        await g.deleteNode('temp');
        const t2 = new Date();

        // Verify
        const resT0 = await g.asOf(t0).match(['Temp']).select();
        expect(resT0.length).toBe(0);

        const resT1 = await g.asOf(t1).match(['Temp']).select();
        expect(resT1.length).toBe(1);
        expect(resT1[0].id).toBe('temp');

        const resT2 = await g.asOf(t2).match(['Temp']).select();
        expect(resT2.length).toBe(0);
      });
    });
  crates/quack_core/src/matcher.rs: >-
    use crate::topology::{GraphIndex, Direction};

    use std::collections::HashSet;


    #[derive(Debug, Clone)]

    pub struct PatternEdge {
        pub src_var: usize,
        pub tgt_var: usize,
        pub type_id: u8,
        pub direction: Direction,
    }


    /// A simple backtracking solver for subgraph isomorphism.

    /// Finds all assignments of graph nodes to pattern variables such that all
    pattern edges exist.

    ///

    /// Assumptions:

    /// 1. Variable 0 is the "start" variable, seeded by `start_candidates`.

    /// 2. The pattern is connected: for any variable `i > 0`, there is at least
    one constraint

    ///    connecting it to a variable `j < i`.

    pub struct Matcher<'a> {
        graph: &'a GraphIndex,
        pattern: &'a [PatternEdge],
        num_vars: usize,
    }


    impl<'a> Matcher<'a> {
        pub fn new(graph: &'a GraphIndex, pattern: &'a [PatternEdge]) -> Self {
            let mut max_var = 0;
            for e in pattern {
                max_var = max_var.max(e.src_var).max(e.tgt_var);
            }
            Self {
                graph,
                pattern,
                num_vars: max_var + 1,
            }
        }

        pub fn find_matches(&self, start_candidates: &[u32]) -> Vec<Vec<u32>> {
            let mut results = Vec::new();
            let mut assignment = vec![None; self.num_vars];
            let mut used_nodes = HashSet::new();

            for &start_node in start_candidates {
                if self.graph.is_node_deleted(start_node) {
                    continue;
                }

                assignment[0] = Some(start_node);
                used_nodes.insert(start_node);
                
                self.backtrack(1, &mut assignment, &mut used_nodes, &mut results);
                
                used_nodes.remove(&start_node);
                assignment[0] = None;
            }

            results
        }

        fn backtrack(
            &self,
            current_var: usize,
            assignment: &mut Vec<Option<u32>>,
            used_nodes: &mut HashSet<u32>,
            results: &mut Vec<Vec<u32>>,
        ) {
            if current_var == self.num_vars {
                results.push(assignment.iter().map(|opt| opt.unwrap()).collect());
                return;
            }

            let mut candidates: Option<Vec<u32>> = None;

            for edge in self.pattern {
                if edge.src_var < current_var && edge.tgt_var == current_var {
                    let known_node = assignment[edge.src_var].unwrap();
                    let neighbors = self.graph.get_neighbors(known_node, edge.type_id, Direction::Outgoing);
                    candidates = self.intersect(candidates, neighbors);
                    if candidates.as_ref().is_some_and(|c| c.is_empty()) { return; }
                }
                else if edge.src_var == current_var && edge.tgt_var < current_var {
                    let known_node = assignment[edge.tgt_var].unwrap();
                    let neighbors = self.graph.get_neighbors(known_node, edge.type_id, Direction::Incoming);
                    candidates = self.intersect(candidates, neighbors);
                    if candidates.as_ref().is_some_and(|c| c.is_empty()) { return; }
                }
            }
            
            if let Some(cands) = candidates {
                for cand in cands {
                    if !used_nodes.contains(&cand) {
                        assignment[current_var] = Some(cand);
                        used_nodes.insert(cand);
                        
                        self.backtrack(current_var + 1, assignment, used_nodes, results);
                        
                        used_nodes.remove(&cand);
                        assignment[current_var] = None;
                    }
                }
            }
        }

        fn intersect(&self, current: Option<Vec<u32>>, next: Vec<u32>) -> Option<Vec<u32>> {
            match current {
                None => Some(next),
                Some(curr) => {
                    let set: HashSet<_> = next.into_iter().collect();
                    Some(curr.into_iter().filter(|id| set.contains(id)).collect())
                }
            }
        }
    }
  packages/quack-graph/src/query.ts: |-
    import type { QuackGraph } from './graph';

    type TraversalStep = {
      type: 'out' | 'in' | 'recursive';
      edge: string;
      direction?: 'out' | 'in';
      bounds?: { min: number; max: number };
    };

    export class QueryBuilder {
      private graph: QuackGraph;
      private startLabels: string[];
      private endLabels: string[] = [];

      // Bottom Bun Filters (Initial selection)
      // biome-ignore lint/suspicious/noExplicitAny: Generic filter criteria
      private initialFilters: Record<string, any> = {};
      private vectorSearch: { vector: number[]; limit: number } | null = null;

      // The Meat (Traversal)
      private traversals: TraversalStep[] = [];

      // Top Bun Filters (Final selection)
      // biome-ignore lint/suspicious/noExplicitAny: Generic filter criteria
      private terminalFilters: Record<string, any> = {};

      private aggState = {
        groupBy: [] as string[],
        orderBy: [] as { field: string; dir: 'ASC' | 'DESC' }[],
        limit: undefined as number | undefined,
        offset: undefined as number | undefined,
      };

      constructor(graph: QuackGraph, labels: string[]) {
        this.graph = graph;
        this.startLabels = labels;
      }

      /**
       * Traverses the graph recursively (BFS) with depth bounds.
       * Useful for variable length paths like `(a)-[:KNOWS*1..5]->(b)`.
       * @param edgeType The edge label to follow.
       * @param options min/max depth (default: 1..5).
       * @param direction 'out' (default) or 'in'.
       */
      recursive(edgeType: string, options: { min?: number; max?: number } = {}, direction: 'out' | 'in' = 'out'): this {
        this.traversals.push({
          type: 'recursive',
          edge: edgeType,
          direction,
          bounds: {
            min: options.min ?? 1,
            max: options.max ?? 5,
          }
        });
        return this;
      }

      /**
       * Filter nodes by properties.
       * If called before traversal, applies to Start Nodes.
       * If called after traversal, applies to End Nodes.
       */
      // biome-ignore lint/suspicious/noExplicitAny: Generic filter criteria
      where(criteria: Record<string, any>): this {
        if (this.traversals.length === 0) {
          this.initialFilters = { ...this.initialFilters, ...criteria };
        } else {
          this.terminalFilters = { ...this.terminalFilters, ...criteria };
        }
        return this;
      }

      /**
       * Perform a Vector Similarity Search (HNSW).
       * This effectively sorts the start nodes by distance to the query vector.
       */
      nearText(vector: number[], options: { limit?: number } = {}): this {
        this.vectorSearch = { 
          vector, 
          limit: options.limit || 10 
        };
        return this;
      }

      out(edgeType: string): this {
        this.traversals.push({ type: 'out', edge: edgeType });
        return this;
      }

      in(edgeType: string): this {
        this.traversals.push({ type: 'in', edge: edgeType });
        return this;
      }

      groupBy(field: string): this {
        this.aggState.groupBy.push(field);
        return this;
      }

      orderBy(field: string, dir: 'ASC' | 'DESC' = 'ASC'): this {
        this.aggState.orderBy.push({ field, dir });
        return this;
      }

      limit(n: number): this {
        this.aggState.limit = n;
        return this;
      }

      offset(n: number): this {
        this.aggState.offset = n;
        return this;
      }

      /**
       * Filter the nodes at the end of the traversal by label.
       */
      node(labels: string[]): this {
        this.endLabels = labels;
        return this;
      }

      /**
       * Helper to construct the temporal validity clause
       */
      private getTemporalClause(tableAlias: string = ''): string {
        const prefix = tableAlias ? `${tableAlias}.` : '';
        if (this.graph.context.asOf) {
          // Time Travel: valid_from <= T AND (valid_to > T OR valid_to IS NULL)
          // Interpolate strict ISO string
          const iso = this.graph.context.asOf.toISOString();
          // DuckDB TIMESTAMP comparison works with ISO strings
          return `(${prefix}valid_from <= '${iso}' AND (${prefix}valid_to > '${iso}' OR ${prefix}valid_to IS NULL))`;
        }
        // Default: Current valid records (valid_to is NULL)
        return `${prefix}valid_to IS NULL`;
      }

      /**
       * Executes the query.
       * @param projection Optional SQL projection string (e.g., 'count(*), avg(properties->>age)') or a JS mapper function.
       */
      // biome-ignore lint/suspicious/noExplicitAny: Generic result mapper
      async select<T = any>(projection?: string | ((node: any) => T)): Promise<T[]> {
        const isRawSql = typeof projection === 'string';
        const mapper = typeof projection === 'function' ? projection : undefined;

        // --- Step 1: DuckDB Filter (Bottom Bun) ---
        // Objective: Get a list of "Active" Node IDs to feed into the graph.

        let query = `SELECT id FROM nodes`;
        // biome-ignore lint/suspicious/noExplicitAny: SQL parameters
        const params: any[] = [];
        const conditions: string[] = [];

        // 1.a Temporal Filter
        conditions.push(this.getTemporalClause());

        // 1.b Label Filter
        if (this.startLabels.length > 0) {
          // Check if ANY of the labels match. For V1 we check the first one or intersection.
          conditions.push(`list_contains(labels, ?)`);
          params.push(this.startLabels[0]);
        }

        // 1.c Property Filter
        for (const [key, value] of Object.entries(this.initialFilters)) {
          if (key === 'id') {
            conditions.push(`id = ?`);
            params.push(value);
          } else {
            conditions.push(`json_extract(properties, '$.${key}') = ?::JSON`);
            params.push(JSON.stringify(value));
          }
        }

        // 1.d Vector Search (Order By Distance)
        let orderBy = '';
        let limit = '';
        if (this.vectorSearch) {
          // Requires: array_distance(embedding, [1,2,3])
          // DuckDB VSS extension syntax
          // Fallback: Use basic array operations since VSS extension has type compatibility issues
          // This implements a simple Euclidean distance calculation
          const vectorValues = this.vectorSearch.vector.map((v, i) => {
            const embeddingElement = `embedding[${i}]`;
            return `POW(COALESCE(${embeddingElement}, 0) - ${v}, 2)`;
          }).join(' + ');
          orderBy = `ORDER BY SQRT(${vectorValues})`;
          limit = `LIMIT ${this.vectorSearch.limit}`;
        }

        if (conditions.length > 0) {
          query += ` WHERE ${conditions.join(' AND ')}`;
        }

        query += ` ${orderBy} ${limit}`;

        const startRows = await this.graph.db.query(query, params);
        let currentIds: string[] = startRows.map(row => row.id);

        if (currentIds.length === 0) return [];

        // --- Step 2: Rust Traversal (The Meat) ---
        // Note: Rust Graph Index is currently "Latest Topology Only". 
        // Time Travel on topology requires checking edge validity during traversal (V2).
        // For V1, we accept that traversal is instant/current, but properties are historical.

        for (const step of this.traversals) {
          if (currentIds.length === 0) break;
          
          if (step.type === 'recursive') {
            currentIds = this.graph.native.traverseRecursive(
              currentIds,
              step.edge,
              step.direction || 'out',
              step.bounds?.min,
              step.bounds?.max
            );
          } else {
            // step.type is 'out' | 'in'
            currentIds = this.graph.native.traverse(currentIds, step.edge, step.type as 'out' | 'in');
          }
        }

        // Optimization: If traversal resulted in no nodes, stop early.
        if (currentIds.length === 0) return [];

        // --- Step 3: DuckDB Hydration (Top Bun) ---
        // Objective: Fetch full properties for the resulting IDs, applying terminal filters.

        const finalConditions: string[] = [];
        // biome-ignore lint/suspicious/noExplicitAny: SQL parameters
        const finalParams: any[] = [];

        // 3.0 Label Filter (for End Nodes)
        if (this.endLabels.length > 0) {
          finalConditions.push(`list_contains(labels, ?)`);
          finalParams.push(this.endLabels[0]);
        }

        // 3.a IDs match
        // We can't use parameters for IN clause effectively with dynamic length in all drivers.
        // Constructing placeholders.
        const placeholders = currentIds.map(() => '?').join(',');
        finalConditions.push(`id IN (${placeholders})`);
        finalParams.push(...currentIds);

        // 3.b Temporal Validity
        finalConditions.push(this.getTemporalClause());

        // 3.c Terminal Property Filters
        for (const [key, value] of Object.entries(this.terminalFilters)) {
          if (key === 'id') {
            finalConditions.push(`id = ?`);
            finalParams.push(value);
          } else {
            finalConditions.push(`json_extract(properties, '$.${key}') = ?::JSON`);
            finalParams.push(JSON.stringify(value));
          }
        }

        // 3.d Aggregation / Grouping / Ordering
        let selectClause = 'SELECT *';
        if (isRawSql) {
          selectClause = `SELECT ${projection}`;
        }

        let suffix = '';
        if (this.aggState.groupBy.length > 0) {
          suffix += ` GROUP BY ${this.aggState.groupBy.join(', ')}`;
        }
        
        if (this.aggState.orderBy.length > 0) {
          const orders = this.aggState.orderBy.map(o => `${o.field} ${o.dir}`).join(', ');
          suffix += ` ORDER BY ${orders}`;
        }

        if (this.aggState.limit !== undefined) {
          suffix += ` LIMIT ${this.aggState.limit}`;
        }
        if (this.aggState.offset !== undefined) {
          suffix += ` OFFSET ${this.aggState.offset}`;
        }

        const finalSql = `${selectClause} FROM nodes WHERE ${finalConditions.join(' AND ')} ${suffix}`;
        const results = await this.graph.db.query(finalSql, finalParams);

        return results.map(r => {
          if (isRawSql) return r;

          let props = r.properties;
          if (typeof props === 'string') {
            try { props = JSON.parse(props); } catch {}
          }
          const node = {
            id: r.id,
            labels: r.labels,
            ...props
          };
          return mapper ? mapper(node) : node;
        });
      }
    }
approved: false
linesAdded: null
linesRemoved: null
linesDifference: null
gitCommittedAt: null
status: undone
id: 56
